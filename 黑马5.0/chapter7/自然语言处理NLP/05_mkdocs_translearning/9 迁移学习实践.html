
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../img/logo.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.1.6">
    
    
      
        <title>9 迁移学习实践 - 自然语言处理基础V4.0</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.cd566b2a.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.e6a45f82.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href=".." title="自然语言处理基础V4.0" class="md-header__button md-logo" aria-label="自然语言处理基础V4.0" data-md-component="logo">
      
  <img src="../img/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            自然语言处理基础V4.0
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              9 迁移学习实践
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    <img src="../assets/images/logo.svg" height="45px" alt="logo">

  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="自然语言处理基础V4.0" class="md-nav__button md-logo" aria-label="自然语言处理基础V4.0" data-md-component="logo">
      
  <img src="../img/logo.png" alt="logo">

    </a>
    自然语言处理基础V4.0
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1">
          第一章 自然语言处理入门
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第一章 自然语言处理入门" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          第一章 自然语言处理入门
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../01_mkdocs_NLP/1_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%85%A5%E9%97%A8.html" class="md-nav__link">
        1 自然语言处理入门
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          第二章 文本预处理
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第二章 文本预处理" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          第二章 文本预处理
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/1%20%E8%AE%A4%E8%AF%86%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86.html" class="md-nav__link">
        1 认识文本预处理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/2%20%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95.html" class="md-nav__link">
        2 文本处理的基本方法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/3%20%E6%96%87%E6%9C%AC%E5%BC%A0%E9%87%8F%E8%A1%A8%E7%A4%BA%E6%96%B9%E6%B3%95.html" class="md-nav__link">
        3 文本张量表示方法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/4%20%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90.html" class="md-nav__link">
        4 文本数据分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/5%20%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86.html" class="md-nav__link">
        5 文本特征处理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/6%20%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA.html" class="md-nav__link">
        6 文本数据增强
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/7%20jieba%E8%AF%8D%E6%80%A7%E5%AF%B9%E7%85%A7%E8%A1%A8.html" class="md-nav__link">
        7 jieba词性对照表
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          第三章 RNN及其变体
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第三章 RNN及其变体" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          第三章 RNN及其变体
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/1%20%E8%AE%A4%E8%AF%86RNN%E6%A8%A1%E5%9E%8B.html" class="md-nav__link">
        1 认识RNN模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/2%20%E4%BC%A0%E7%BB%9FRNN%E6%A8%A1%E5%9E%8B.html" class="md-nav__link">
        2 传统RNN模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/3%20LSTM%E6%A8%A1%E5%9E%8B.html" class="md-nav__link">
        3 LSTM模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/4%20GRU%E6%A8%A1%E5%9E%8B.html" class="md-nav__link">
        4 GRU模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/5%20RNN%E6%A1%88%E4%BE%8B-%E4%BA%BA%E5%90%8D%E5%88%86%E7%B1%BB%E5%99%A8.html" class="md-nav__link">
        5 RNN案例 人名分类器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/6%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D1.html" class="md-nav__link">
        6 注意力机制介绍1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/7%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D2.html" class="md-nav__link">
        7 注意力机制介绍2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/8%20RNN%E6%A1%88%E4%BE%8B-seq2seq%E8%8B%B1%E8%AF%91%E6%B3%95.html" class="md-nav__link">
        8 RNN案例 seq2seq英译法
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          第四章 Transformer
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第四章 Transformer" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          第四章 Transformer
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/1%20Transformer%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        1 Transformer背景介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/2%20%E8%AE%A4%E8%AF%86Transformer%E6%9E%B6%E6%9E%84.html" class="md-nav__link">
        2 认识Transformer架构
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/3%20%E8%BE%93%E5%85%A5%E9%83%A8%E5%88%86%E5%AE%9E%E7%8E%B0.html" class="md-nav__link">
        3 输入部分实现
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/4%20%E7%BC%96%E7%A0%81%E5%99%A8%E9%83%A8%E5%88%86%E5%AE%9E%E7%8E%B0.html" class="md-nav__link">
        4 编码器部分实现
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/5%20%E8%A7%A3%E7%A0%81%E5%99%A8%E9%83%A8%E5%88%86%E5%AE%9E%E7%8E%B0.html" class="md-nav__link">
        5 解码器部分实现
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/6%20%E8%BE%93%E5%87%BA%E9%83%A8%E5%88%86%E5%AE%9E%E7%8E%B0.html" class="md-nav__link">
        6 输出部分实现
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/7%20%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA.html" class="md-nav__link">
        7 模型构建
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          第五章 迁移学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第五章 迁移学习" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          第五章 迁移学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="1%20fasttext%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        1 fasttext工具介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="2%20fasttext%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84.html" class="md-nav__link">
        2 fasttext模型架构
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="3%20fasttext%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html" class="md-nav__link">
        3 fasttext文本分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="4%20%E8%AE%AD%E7%BB%83%E8%AF%8D%E5%90%91%E9%87%8F.html" class="md-nav__link">
        4 训练词向量
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="5%20%E8%AF%8D%E5%90%91%E9%87%8F%E8%BF%81%E7%A7%BB.html" class="md-nav__link">
        5 词向量迁移
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="6%20%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5.html" class="md-nav__link">
        6 迁移学习概念
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="7%20NLP%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B.html" class="md-nav__link">
        7 NLP中的常用预训练模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="8%20Transformers%E5%BA%93%E4%BD%BF%E7%94%A8.html" class="md-nav__link">
        8 Transformers库使用
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          9 迁移学习实践
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="9%20%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5.html" class="md-nav__link md-nav__link--active">
        9 迁移学习实践
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    学习目标
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    1 通过微调方式进行迁移学习的两种类型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-" class="md-nav__link">
    2 迁移学习-中文分类
  </a>
  
    <nav class="md-nav" aria-label="2 迁移学习-中文分类">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_1" class="md-nav__link">
    1 任务介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    2 数据介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    3 数据预处理
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    4 自定义下游任务网络模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    5 模型训练
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6" class="md-nav__link">
    6 模型评估
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-" class="md-nav__link">
    3 迁移学习-中文填空
  </a>
  
    <nav class="md-nav" aria-label="3 迁移学习-中文填空">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_2" class="md-nav__link">
    1 任务介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_1" class="md-nav__link">
    2 数据介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_1" class="md-nav__link">
    3 数据预处理
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_1" class="md-nav__link">
    4 自定义下游任务网络模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5_1" class="md-nav__link">
    5 模型训练
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6_1" class="md-nav__link">
    6 模型评估
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-" class="md-nav__link">
    4 迁移学习-中文句子关系
  </a>
  
    <nav class="md-nav" aria-label="4 迁移学习-中文句子关系">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_3" class="md-nav__link">
    1 任务介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_2" class="md-nav__link">
    2 数据介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_2" class="md-nav__link">
    3 数据预处理
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_2" class="md-nav__link">
    4 自定义下游任务网络模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5_2" class="md-nav__link">
    5 模型训练
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6_2" class="md-nav__link">
    6 模型评估
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-" class="md-nav__link">
    5 迁移学习-微调脚本中文分类
  </a>
  
    <nav class="md-nav" aria-label="5 迁移学习-微调脚本中文分类">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_4" class="md-nav__link">
    1 数据介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_3" class="md-nav__link">
    2 运行代码
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_3" class="md-nav__link">
    3 查看模型文件内容
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_3" class="md-nav__link">
    4 使用本地微调模型
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6_3" class="md-nav__link">
    6 小结
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="10%20NLP%E4%B8%AD%E7%9A%84%E6%A0%87%E5%87%86%E6%95%B0%E6%8D%AE%E9%9B%86%28%E6%8B%93%E5%B1%95%E8%B5%84%E6%96%99%29.html" class="md-nav__link">
        10 NLP中的标准数据集(拓展资料)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          第六章 Bert系列模型
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第六章 Bert系列模型" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          第六章 Bert系列模型
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_mkdocs_bert_pretrained_model/1%20BERT%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        1 BERT模型介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_mkdocs_bert_pretrained_model/2%20BERT%E6%A8%A1%E5%9E%8B%E7%89%B9%E7%82%B9.html" class="md-nav__link">
        2 BERT模型特点
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_mkdocs_bert_pretrained_model/3%20BERT%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        3 BERT系列模型介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_mkdocs_bert_pretrained_model/4%20ELMo%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        4 ELMo模型介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_mkdocs_bert_pretrained_model/5%20GPT%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        5 GPT模型介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_mkdocs_bert_pretrained_model/6%20BERT%20GPT%20ELMo%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AF%B9%E6%AF%94.html" class="md-nav__link">
        6 BERT GPT ELMo模型的对比
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7">
          第七章 Transformer精选问答(拓展资料)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第七章 Transformer精选问答(拓展资料)" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          第七章 Transformer精选问答(拓展资料)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_mkdocs_review_model/1%20Transformer%20%E5%90%84%E5%AD%90%E6%A8%A1%E5%9D%97%E4%BD%9C%E7%94%A8.html" class="md-nav__link">
        1 Transformer 各子模块作用
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_mkdocs_review_model/2%20Transformer%20Decoder%E6%A8%A1%E5%9D%97.html" class="md-nav__link">
        2 Transformer Decoder模块
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_mkdocs_review_model/3%20Self-attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3.html" class="md-nav__link">
        3 Self attention机制详解
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_mkdocs_review_model/4%20Multi-head%20Attention%E8%AF%A6%E8%A7%A3.html" class="md-nav__link">
        4 Multi head Attention详解
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_mkdocs_review_model/5%20Transformer%E4%BC%98%E5%8A%BF.html" class="md-nav__link">
        5 Transformer优势
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    学习目标
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    1 通过微调方式进行迁移学习的两种类型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-" class="md-nav__link">
    2 迁移学习-中文分类
  </a>
  
    <nav class="md-nav" aria-label="2 迁移学习-中文分类">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_1" class="md-nav__link">
    1 任务介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    2 数据介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    3 数据预处理
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    4 自定义下游任务网络模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    5 模型训练
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6" class="md-nav__link">
    6 模型评估
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-" class="md-nav__link">
    3 迁移学习-中文填空
  </a>
  
    <nav class="md-nav" aria-label="3 迁移学习-中文填空">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_2" class="md-nav__link">
    1 任务介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_1" class="md-nav__link">
    2 数据介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_1" class="md-nav__link">
    3 数据预处理
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_1" class="md-nav__link">
    4 自定义下游任务网络模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5_1" class="md-nav__link">
    5 模型训练
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6_1" class="md-nav__link">
    6 模型评估
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-" class="md-nav__link">
    4 迁移学习-中文句子关系
  </a>
  
    <nav class="md-nav" aria-label="4 迁移学习-中文句子关系">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_3" class="md-nav__link">
    1 任务介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_2" class="md-nav__link">
    2 数据介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_2" class="md-nav__link">
    3 数据预处理
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_2" class="md-nav__link">
    4 自定义下游任务网络模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5_2" class="md-nav__link">
    5 模型训练
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6_2" class="md-nav__link">
    6 模型评估
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-" class="md-nav__link">
    5 迁移学习-微调脚本中文分类
  </a>
  
    <nav class="md-nav" aria-label="5 迁移学习-微调脚本中文分类">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_4" class="md-nav__link">
    1 数据介绍
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_3" class="md-nav__link">
    2 运行代码
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3_3" class="md-nav__link">
    3 查看模型文件内容
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4_3" class="md-nav__link">
    4 使用本地微调模型
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6_3" class="md-nav__link">
    6 小结
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                

  <h1>9 迁移学习实践</h1>

<h3 id="_1">学习目标<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h3>
<ul>
<li>了解并掌握迁移学习-中文分类任务开发</li>
<li>了解并掌握迁移学习-中文填空任务开发</li>
<li>了解并掌握迁移学习-中文句子关系任务</li>
<li>了解通过微调脚本微调后模型的使用方法</li>
</ul>
<h2 id="1">1 通过微调方式进行迁移学习的两种类型<a class="headerlink" href="#1" title="Permanent link">&para;</a></h2>
<ul>
<li>类型一: 直接加载预训练模型进行输入文本的特征表示, 后接自定义网络进行微调输出结果</li>
<li>类型二: 使用指定任务类型的微调脚本微调预训练模型, 后接带有输出头的预定义网络输出结果</li>
<li>说明: 所有类型的实战演示, 都将针对中文文本进行</li>
</ul>
<h2 id="2-">2 迁移学习-中文分类<a class="headerlink" href="#2-" title="Permanent link">&para;</a></h2>
<h3 id="1_1">1 任务介绍<a class="headerlink" href="#1_1" title="Permanent link">&para;</a></h3>
<ul>
<li>直接加载预训练模型进行输入文本的特征表示, 后接自定义网络进行微调输出结果</li>
</ul>
<h3 id="2">2 数据介绍<a class="headerlink" href="#2" title="Permanent link">&para;</a></h3>
<ul>
<li>数据文件有三个train.csv，test.csv，validation.csv，数据样式都是一样的。</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">label</span><span class="p">,</span><span class="n">text</span>
<span class="mi">1</span><span class="p">,</span><span class="n">选择珠江花园的原因就是方便</span><span class="err">，</span><span class="n">有电动扶梯直接到达海边</span><span class="err">，</span><span class="n">周围餐馆</span><span class="err">、</span><span class="n">食廊</span><span class="err">、</span><span class="n">商场</span><span class="err">、</span><span class="n">超市</span><span class="err">、</span><span class="n">摊位一应俱全</span><span class="err">。</span><span class="n">酒店装修一般</span><span class="err">，</span><span class="n">但还算整洁</span><span class="err">。</span> <span class="n">泳池在大堂的屋顶</span><span class="err">，</span><span class="n">因此很小</span><span class="err">，</span><span class="n">不过女儿倒是喜欢</span><span class="err">。</span> <span class="n">包的早餐是西式的</span><span class="err">，</span><span class="n">还算丰富</span><span class="err">。</span> <span class="n">服务吗</span><span class="err">，</span><span class="n">一般</span>
<span class="mi">1</span><span class="p">,</span><span class="mf">15.4</span><span class="n">寸笔记本的键盘确实爽</span><span class="err">，</span><span class="n">基本跟台式机差不多了</span><span class="err">，</span><span class="n">蛮喜欢数字小键盘</span><span class="err">，</span><span class="n">输数字特方便</span><span class="err">，</span><span class="n">样子也很美观</span><span class="err">，</span><span class="n">做工也相当不错</span>
<span class="mi">0</span><span class="p">,</span><span class="n">房间太小</span><span class="err">。</span><span class="n">其他的都一般</span><span class="err">。。。。。。。。。</span>
<span class="mi">0</span><span class="p">,</span><span class="s2">&quot;1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸，一摸一个印. 4.硬盘分区不好办.&quot;</span>
<span class="mi">1</span><span class="p">,</span><span class="s2">&quot;今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量商量,单独出个第6卷,让我们的孩子不会有所遗憾。&quot;</span>
</code></pre></div>
<ul>
<li>通过huggingface的datasets工具，加载信息文件信息如下</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">加载训练集</span>
<span class="n">dataset_train</span><span class="o">---&gt;</span> <span class="n">Dataset</span><span class="p">({</span>
    <span class="n">features</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">],</span>
    <span class="n">num_rows</span><span class="p">:</span> <span class="mi">9600</span>
<span class="p">})</span>
<span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般&#39;</span><span class="p">,</span> <span class="s1">&#39;15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错&#39;</span><span class="p">,</span> <span class="s1">&#39;房间太小。其他的都一般。。。。。。。。。&#39;</span><span class="p">]}</span>

<span class="n">加载测试集</span>
<span class="n">my_dataset_test</span><span class="o">---&gt;</span> <span class="n">Dataset</span><span class="p">({</span>
    <span class="n">features</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">],</span>
    <span class="n">num_rows</span><span class="p">:</span> <span class="mi">1200</span>
<span class="p">})</span>
<span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般&#39;</span><span class="p">,</span> <span class="s1">&#39;怀着十分激动的心情放映，可是看着看着发现，在放映完毕后，出现一集米老鼠的动画片！开始还怀疑是不是赠送的个别现象，可是后来发现每张DVD后面都有！真不知道生产商怎么想的，我想看的是猫和老鼠，不是米老鼠！如果厂家是想赠送的话，那就全套米老鼠和唐老鸭都赠送，只在每张DVD后面添加一集算什么？？简直是画蛇添足！！&#39;</span><span class="p">,</span> <span class="s1">&#39;还稍微重了点，可能是硬盘大的原故，还要再轻半斤就好了。其他要进一步验证。贴的几种膜气泡较多，用不了多久就要更换了，屏幕膜稍好点，但比没有要强多了。建议配赠几张膜让用用户自己贴。&#39;</span><span class="p">]}</span>

<span class="n">加载验证集</span>
<span class="n">my_dataset_validation</span><span class="o">---&gt;</span> <span class="n">Dataset</span><span class="p">({</span>
    <span class="n">features</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">],</span>
    <span class="n">num_rows</span><span class="p">:</span> <span class="mi">1200</span>
<span class="p">})</span>
<span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;這間酒店環境和服務態度亦算不錯,但房間空間太小~~不宣容納太大件行李~~且房間格調還可以~~ 中餐廳的廣東點心不太好吃~~要改善之~~~~但算價錢平宜~~可接受~~ 西餐廳格調都很好~~但吃的味道一般且令人等得太耐了~~要改善之~~&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;荐书&gt; 推荐所有喜欢&lt;红楼&gt;的红迷们一定要收藏这本书,要知道当年我听说这本书的时候花很长时间去图书馆找和借都没能如愿,所以这次一看到当当有,马上买了,红迷们也要记得备货哦!&#39;</span><span class="p">,</span> <span class="s1">&#39;商品的不足暂时还没发现，京东的订单处理速度实在.......周二就打包完成，周五才发货...&#39;</span><span class="p">]}</span>
</code></pre></div>
<ul>
<li>通过huggingface的datasets工具，加载代码如下</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">dm_file2dataset</span><span class="p">():</span>

    <span class="c1"># 实例化数据源对象my_dataset_train</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">加载训练集&#39;</span><span class="p">)</span>
    <span class="n">my_dataset_train</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s1">&#39;./mydata1/train.csv&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dataset_train---&gt;&#39;</span><span class="p">,</span> <span class="n">my_dataset_train</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">my_dataset_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>

    <span class="c1"># 实例化数据源对象my_dataset_test</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">加载测试集&#39;</span><span class="p">)</span>
    <span class="n">my_dataset_test</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s1">&#39;./mydata1/test.csv&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;my_dataset_test---&gt;&#39;</span><span class="p">,</span> <span class="n">my_dataset_test</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">my_dataset_test</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">加载验证集&#39;</span><span class="p">)</span>
    <span class="c1"># 实例化数据源对象my_dataset_train</span>
    <span class="n">my_dataset_validation</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s1">&#39;./mydata1/validation.csv&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;my_dataset_validation---&gt;&#39;</span><span class="p">,</span> <span class="n">my_dataset_validation</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">my_dataset_validation</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
</code></pre></div>
<ul>
<li>导入工具包和辅助工具实例化对象</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># 导入工具包</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertModel</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># 加载字典和分词工具 实例化分词工具</span>
<span class="n">my_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-chinese&#39;</span><span class="p">)</span>

<span class="c1"># 加载预训练模型 实例化预训练模型</span>
<span class="n">my_model_pretrained</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-chinese&#39;</span><span class="p">)</span>
</code></pre></div>
<h3 id="3">3 数据预处理<a class="headerlink" href="#3" title="Permanent link">&para;</a></h3>
<p>对持久化文件中数据进行处理，以满足模型训练要求。</p>
<blockquote>
<ul>
<li>数据预处理和相关测试函数</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="c1"># 数据集处理自定义函数</span>
<span class="k">def</span> <span class="nf">collate_fn1</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>

    <span class="c1"># data传过来的数据是list eg: 批次数8，8个字典</span>
    <span class="c1"># [{&#39;text&#39;:&#39;xxxx&#39;,&#39;label&#39;:0} , {&#39;text&#39;:&#39;xxxx&#39;,&#39;label&#39;:1}, ...]</span>
    <span class="n">sents</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>

    <span class="c1"># 编码text2id 对多句话进行编码用batch_encode_plus函数</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">my_tokenizer</span><span class="o">.</span><span class="n">batch_encode_plus</span><span class="p">(</span><span class="n">batch_text_or_text_pairs</span><span class="o">=</span><span class="n">sents</span><span class="p">,</span>
                                   <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                   <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span>
                                   <span class="n">max_length</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
                                   <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">,</span>
                                   <span class="n">return_length</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># input_ids:编码之后的数字</span>
    <span class="c1"># attention_mask:是补零的位置是0,其他位置是1</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span>
    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span>
    <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;token_type_ids&#39;</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

    <span class="c1"># 返回text2id信息 掩码信息 句子分段信息 标签y</span>
    <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">labels</span>


<span class="c1"># 测试数据</span>
<span class="k">def</span> <span class="nf">dm01_test_dataset</span><span class="p">():</span>

    <span class="c1"># 实例化数据源 通过训练文件</span>
    <span class="n">dataset_train</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s1">&#39;./mydata1/train.csv&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dataset_train---&gt;&#39;</span><span class="p">,</span> <span class="n">dataset_train</span><span class="p">)</span>

    <span class="c1"># 实例化数据迭代器 mydataloader</span>
    <span class="n">mydataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset_train</span><span class="p">,</span>
                                               <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                               <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn1</span><span class="p">,</span>
                                               <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                               <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mydataloader---&gt;&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mydataloader</span><span class="p">))</span>

    <span class="c1"># 调整数据迭代器对象数据返回格式</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mydataloader</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mydataloader</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="c1"># 打印句子text2id后的信息</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">)</span>
        <span class="c1"># 打印句子attention掩码信息</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>
        <span class="c1"># 打印句子分段信息</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;token_type_ids&#39;</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">)</span>
        <span class="c1"># 打印目标y信息</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;labels&#39;</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="k">break</span>
</code></pre></div>
<blockquote>
<ul>
<li>程序运行效果</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="c1"># 显示训练集字段和样本数目</span>
<span class="n">dataset_train</span><span class="o">---&gt;</span> <span class="n">Dataset</span><span class="p">({</span>
    <span class="n">features</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">],</span>
    <span class="n">num_rows</span><span class="p">:</span> <span class="mi">9600</span>
<span class="p">})</span>
<span class="n">mydataloader</span><span class="o">---&gt;</span> <span class="mi">1200</span>

<span class="c1"># 显示处理后送给模型的数据信息</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">500</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">500</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">500</span><span class="p">])</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1"># 句子text2id后的信息</span>
<span class="n">input_ids</span> <span class="n">tensor</span><span class="p">([[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">6848</span><span class="p">,</span> <span class="mi">2885</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">8115</span><span class="p">,</span>  <span class="mi">119</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">2791</span><span class="p">,</span> <span class="mi">7313</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
        <span class="o">...</span><span class="p">,</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">3322</span><span class="p">,</span> <span class="mi">1690</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">1457</span><span class="p">,</span> <span class="mi">1457</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">6821</span><span class="p">,</span> <span class="mi">3315</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">]])</span>

<span class="c1"># 句子注意力机制掩码信息</span>
<span class="n">attention_mask</span> <span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="o">...</span><span class="p">,</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

<span class="c1"># 句子分段信息</span>
<span class="n">token_type_ids</span> <span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="o">...</span><span class="p">,</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

<span class="c1"># 句子的标签信息</span>
<span class="n">labels</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</code></pre></div>
<h3 id="4">4 自定义下游任务网络模型<a class="headerlink" href="#4" title="Permanent link">&para;</a></h3>
<p>自定义单层的全连接网络作为微调网络。根据实际经验, 自定义的微调网络参数总数应大于0.5倍的训练数据量, 小于10倍的训练数据量, 这样有助于模型在合理的时间范围内收敛</p>
<blockquote>
<ul>
<li>自定义下游任务网络模型</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="c1"># 定义下游任务模型</span>
<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># 定义全连接层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">):</span>

        <span class="c1"># 预训练模型不训练 只进行特征抽取 [8,500] ---&gt; [8,768]</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">my_model_pretrained</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
                       <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                       <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">)</span>

        <span class="c1"># 下游任务模型训练 数据经过全连接层 [8,768] --&gt; [8,2]</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>

        <span class="c1"># 数据进行softmax归一化 分类概率值</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
</code></pre></div>
<blockquote>
<ul>
<li>模型测试</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="c1"># 下游任务模型输入和输出测试</span>
<span class="k">def</span> <span class="nf">dm02_test_mymodel</span><span class="p">():</span>

    <span class="c1"># 实例化数据源 通过训练文件</span>
    <span class="n">dataset_train</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s1">&#39;./mydata1/train.csv&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="c1"># print(&#39;dataset_train---&gt;&#39;, dataset_train)</span>

    <span class="c1"># 实例化数据迭代器 mydataloader</span>
    <span class="n">mydataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset_train</span><span class="p">,</span>
                                               <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                               <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn1</span><span class="p">,</span>
                                               <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                               <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># print(&#39;mydataloader---&gt;&#39;, len(mydataloader))</span>

    <span class="c1"># 实例化下游任务模型</span>
    <span class="n">mymodel</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mymodel---&gt;&#39;</span><span class="p">,</span> <span class="n">mymodel</span><span class="p">)</span>

    <span class="c1"># 调整数据迭代器对象数据返回格式</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mydataloader</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mydataloader</span><span class="p">))</span>
        <span class="c1"># print(input_ids.shape, attention_mask.shape, token_type_ids.shape, labels)</span>

        <span class="c1"># 数据送给模型</span>
        <span class="n">y_out</span> <span class="o">=</span> <span class="n">mymodel</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y_out----&gt;&#39;</span><span class="p">,</span> <span class="n">y_out</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_out</span><span class="p">)</span>
        <span class="k">break</span>
</code></pre></div>
<blockquote>
<ul>
<li>输出效果</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code># 模型信息打印
mymodel---&gt; MyModel(
  (fc): Linear(in_features=768, out_features=2, bias=True)
)

# 模型运算后分类结果展示
y_out----&gt; torch.Size([8, 2]) tensor([[0.4062, 0.5938],
        [0.2788, 0.7212],
        [0.3671, 0.6329],
        [0.2496, 0.7504],
        [0.2995, 0.7005],
        [0.2566, 0.7434],
        [0.2537, 0.7463],
        [0.3832, 0.6168]], grad_fn=&lt;SoftmaxBackward&gt;)
</code></pre></div>
<h3 id="5">5 模型训练<a class="headerlink" href="#5" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># 模型训练</span>
<span class="k">def</span> <span class="nf">dm03_train_model</span><span class="p">():</span>

    <span class="c1"># 实例化下游任务模型my_model</span>
    <span class="n">my_model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>

    <span class="c1"># 实例化优化器my_optimizer</span>
    <span class="n">my_optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">my_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>

    <span class="c1"># 实例化损失函数my_criterion</span>
    <span class="n">my_criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="c1"># 实例化数据源对象my_dataset_train</span>
    <span class="n">my_dataset_train</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s1">&#39;./mydata1/train.csv&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dataset_train---&gt;&#39;</span><span class="p">,</span> <span class="n">my_dataset_train</span><span class="p">)</span>

    <span class="c1"># 不训练预训练模型 只让预训练模型计算数据特征 不需要计算梯度</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">my_model_pretrained</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># 设置训练参数</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="c1"># 设置模型为训练模型</span>
    <span class="n">my_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># 外层for循环 控制轮数</span>
    <span class="k">for</span> <span class="n">eporch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>

        <span class="c1"># 每次轮次开始计算时间</span>
        <span class="n">starttime</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">)(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span>
        <span class="c1"># 实例化数据迭代器对象my_dataloader</span>
        <span class="n">my_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">my_dataset_train</span><span class="p">,</span>
                                                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                                    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn1</span><span class="p">,</span>
                                                    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                    <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># 内层for循环 控制迭代次数</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">my_dataloader</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>

            <span class="c1"># 给模型喂数据 [8,500] --&gt; [8,2]</span>
            <span class="n">my_out</span> <span class="o">=</span> <span class="n">my_model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
                        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                        <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">)</span>

            <span class="c1"># 计算损失</span>
            <span class="n">my_loss</span> <span class="o">=</span> <span class="n">my_criterion</span><span class="p">(</span><span class="n">my_out</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="c1"># 梯度清零</span>
            <span class="n">my_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># 反向传播</span>
            <span class="n">my_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="c1"># 梯度更新</span>
            <span class="n">my_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># 每5次迭代 算一下准确率</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">my_out</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># [8,2] --&gt; (8,)</span>
                <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">out</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;轮次:</span><span class="si">%d</span><span class="s1"> 迭代数:</span><span class="si">%d</span><span class="s1"> 损失:</span><span class="si">%.6f</span><span class="s1"> 准确率</span><span class="si">%.3f</span><span class="s1"> 时间</span><span class="si">%d</span><span class="s1">&#39;</span> \
                      <span class="o">%</span><span class="p">(</span><span class="n">eporch_idx</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">my_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">)(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="o">-</span><span class="n">starttime</span><span class="p">))</span>

        <span class="c1"># 每个轮次保存模型</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">my_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;./my_model_</span><span class="si">%d</span><span class="s1">.bin&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">eporch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</code></pre></div>
<blockquote>
<ul>
<li>模型训练效果输出</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">5</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.735494</span> <span class="n">准确率0</span><span class="mf">.250</span> <span class="n">时间40</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">10</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.614211</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间81</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">15</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.635408</span> <span class="n">准确率0</span><span class="mf">.750</span> <span class="n">时间119</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">20</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.575522</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间157</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">25</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.661196</span> <span class="n">准确率0</span><span class="mf">.625</span> <span class="n">时间196</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">30</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.546462</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间234</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">35</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.609517</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间272</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">40</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.529246</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间310</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">45</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.474820</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间348</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">50</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.540127</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间387</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">55</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.575326</span> <span class="n">准确率0</span><span class="mf">.625</span> <span class="n">时间426</span>
<span class="c1"># 从以上的训练输出效果来看，预训练模型是十分强大的，只需要短短的几次迭代，就可以让准确率上88%</span>
</code></pre></div>
<h3 id="6">6 模型评估<a class="headerlink" href="#6" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># 模型测试</span>
<span class="k">def</span> <span class="nf">dm04_evaluate_model</span><span class="p">():</span>

    <span class="c1"># 实例化数据源对象my_dataset_test</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">加载测试集&#39;</span><span class="p">)</span>
    <span class="n">my_dataset_test</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s1">&#39;./mydata1/test.csv&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;my_dataset_test---&gt;&#39;</span><span class="p">,</span> <span class="n">my_dataset_test</span><span class="p">)</span>
    <span class="c1"># print(my_dataset_test[0:3])</span>

    <span class="c1"># 实例化下游任务模型my_model</span>
    <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;./my_model_3.bin&#39;</span>
    <span class="n">my_model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
    <span class="n">my_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;my_model--&gt;&#39;</span><span class="p">,</span> <span class="n">my_model</span><span class="p">)</span>

    <span class="c1"># 设置下游任务模型为评估模式</span>
    <span class="n">my_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># 设置评估参数</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># 实例化化dataloader</span>
    <span class="n">my_loader_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">my_dataset_test</span><span class="p">,</span>
                                              <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                              <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn1</span><span class="p">,</span>
                                              <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                              <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># 给模型送数据 测试预测结果</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span>
            <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">my_loader_test</span><span class="p">):</span>

        <span class="c1"># 预训练模型进行特征抽取</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">my_out</span> <span class="o">=</span> <span class="n">my_model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
                        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                        <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">)</span>

        <span class="c1"># 贪心算法求预测结果</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">my_out</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 计算准确率</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">out</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="c1"># 每5次迭代打印一次准确率</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;预测值 真实值:&#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</code></pre></div>
<blockquote>
<ul>
<li>输出效果:</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code>0.875 我 没 有 收 到 这 本 书 ， 我 明 明 和 另 外 一 本 一 起 买 的 ， 服 务 也 不 好 。 至 少 应 该 让 我 知 道 这 个 情 况 在 ！ 预测值 真实值: 0 0
0.8125 也 许 这 不 算 一 个 很 好 的 理 由, 但 是 我 之 所 以 喜 欢 读 书 而 不 是 看 网 上 的 资 料 什 么 的, 就 是 喜 欢 闻 着 书 香. 这 本 书 可 能 是 印 刷 的 油 墨 不 好 还 是 什 么 原 因, 感 觉 臭 臭 的 不 好 闻. 里 面 是 一 些 关 于 中 式 英 语 的 小 趣 闻, 有 些 小 乐 趣, 但 感 觉 对 于 有 浓 重 中 式 思 维 习 惯 说 英 说 的 人 来 说 才 比 较 有 点 用 处. 预测值 真实值: 1 0
0.8409090909090909 1. 有 急 事 出 去 ， 要 们 童 叫 出 租 车 ， 他 们 就 叫 酒 店 里 的 黑 车 ， 价 格 是 普 通 出 租 价 的 两 倍 。 你 提 出 不 要 酒 店 的 黑 车 时 ， 他 们 就 告 诉 你 外 面 拦 不 到 出 租 车 ， 我 们 自 己 走 出 去 时 ， 外 面 出 租 车 随 时 可 以 拦 到 。 住 店 期 间 不 止 一 次 发 生 。 预测值 真实值: 0 0
0.828125 这 本 书 中 的 图 片 很 让 人 触 动 ， 比 如 为 劳 拉 祈 祷 的 校 友 ， 惠 特 尼 和 马 特 的 笑 容 ， 很 动 人 。 预测值 真实值: 1 1
0.8511904761904762 这 是 我 住 过 的 最 差 的 酒 店 ， 房 间 气 味 难 闻 ， 刚 打 了 灭 蚊 药 水 ， 换 了 三 个 房 间 还 是 如 此 ， 服 务 员 说 ： 住 久 了 就 习 惯 了 ， 每 个 宾 馆 都 有 自 己 的 味 道 。 考 ！ 我 又 不 是 来 体 验 生 活 的 。 周 围 环 境 复 杂 ， 脏 乱 差 。 预测值 真实值: 0 0
</code></pre></div>
<h2 id="3-">3 迁移学习-中文填空<a class="headerlink" href="#3-" title="Permanent link">&para;</a></h2>
<h3 id="1_2">1 任务介绍<a class="headerlink" href="#1_2" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># 输入一句话，MASK一个字，训练模型进行填空</span>
<span class="p">[</span><span class="n">CLS</span><span class="p">]</span> <span class="n">选</span> <span class="n">择</span> <span class="n">珠</span> <span class="n">江</span> <span class="n">花</span> <span class="n">园</span> <span class="n">的</span> <span class="n">原</span> <span class="n">因</span> <span class="n">就</span> <span class="n">是</span> <span class="n">方</span> <span class="n">便</span> <span class="err">，</span> <span class="n">有</span> <span class="p">[</span><span class="n">MASK</span><span class="p">]</span> <span class="n">动</span> <span class="n">扶</span> <span class="n">梯</span> <span class="n">直</span> <span class="n">接</span> <span class="n">到</span> <span class="n">达</span> <span class="n">海</span> <span class="n">边</span> <span class="err">，</span> <span class="n">周</span> <span class="n">围</span> <span class="n">餐</span> <span class="n">馆</span> <span class="p">[</span><span class="n">SEP</span><span class="p">]</span>
<span class="c1"># 本句MASK的字为“电”</span>
</code></pre></div>
<h3 id="2_1">2 数据介绍<a class="headerlink" href="#2_1" title="Permanent link">&para;</a></h3>
<ul>
<li>数据文件有三个train.csv，test.csv，validation.csv，数据样式都是一样的。</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">label</span><span class="p">,</span><span class="n">text</span>
<span class="mi">1</span><span class="p">,</span><span class="n">选择珠江花园的原因就是方便</span><span class="err">，</span><span class="n">有电动扶梯直接到达海边</span><span class="err">，</span><span class="n">周围餐馆</span><span class="err">、</span><span class="n">食廊</span><span class="err">、</span><span class="n">商场</span><span class="err">、</span><span class="n">超市</span><span class="err">、</span><span class="n">摊位一应俱全</span><span class="err">。</span><span class="n">酒店装修一般</span><span class="err">，</span><span class="n">但还算整洁</span><span class="err">。</span> <span class="n">泳池在大堂的屋顶</span><span class="err">，</span><span class="n">因此很小</span><span class="err">，</span><span class="n">不过女儿倒是喜欢</span><span class="err">。</span> <span class="n">包的早餐是西式的</span><span class="err">，</span><span class="n">还算丰富</span><span class="err">。</span> <span class="n">服务吗</span><span class="err">，</span><span class="n">一般</span>
<span class="mi">1</span><span class="p">,</span><span class="mf">15.4</span><span class="n">寸笔记本的键盘确实爽</span><span class="err">，</span><span class="n">基本跟台式机差不多了</span><span class="err">，</span><span class="n">蛮喜欢数字小键盘</span><span class="err">，</span><span class="n">输数字特方便</span><span class="err">，</span><span class="n">样子也很美观</span><span class="err">，</span><span class="n">做工也相当不错</span>
<span class="mi">0</span><span class="p">,</span><span class="n">房间太小</span><span class="err">。</span><span class="n">其他的都一般</span><span class="err">。。。。。。。。。</span>
<span class="mi">0</span><span class="p">,</span><span class="s2">&quot;1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸，一摸一个印. 4.硬盘分区不好办.&quot;</span>
<span class="mi">1</span><span class="p">,</span><span class="s2">&quot;今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量商量,单独出个第6卷,让我们的孩子不会有所遗憾。&quot;</span>
</code></pre></div>
<ul>
<li>导入工具包和辅助工具实例化对象</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertModel</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># 加载字典和分词工具</span>
<span class="n">my_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-chinese&#39;</span><span class="p">)</span>

<span class="c1"># 加载预训练模型</span>
<span class="n">my_model_pretrained</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-chinese&#39;</span><span class="p">)</span>
</code></pre></div>
<h3 id="3_1">3 数据预处理<a class="headerlink" href="#3_1" title="Permanent link">&para;</a></h3>
<p>对持久化文件中数据进行处理，以满足模型训练要求。</p>
<blockquote>
<ul>
<li>数据预处理和相关测试函数</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="c1"># 数据集处理自定义函数</span>
<span class="k">def</span> <span class="nf">collate_fn2</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">sents</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>

    <span class="c1"># 文本数值化</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">my_tokenizer</span><span class="o">.</span><span class="n">batch_encode_plus</span><span class="p">(</span><span class="n">batch_text_or_text_pairs</span><span class="o">=</span><span class="n">sents</span><span class="p">,</span>
                                   <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                   <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span>
                                   <span class="n">max_length</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                                   <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">,</span>
                                   <span class="n">return_length</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># input_ids 编码之后的数字</span>
    <span class="c1"># attention_mask 是补零的位置是0,其他位置是1</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span>
    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span>
    <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;token_type_ids&#39;</span><span class="p">]</span>

    <span class="c1"># 把第16个词固定替换为mask</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[:,</span> <span class="mi">16</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>  <span class="c1"># 取出数据8句话 在第16个位置clone出来 做标签</span>
    <span class="n">input_ids</span><span class="p">[:,</span> <span class="mi">16</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_tokenizer</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()[</span><span class="n">my_tokenizer</span><span class="o">.</span><span class="n">mask_token</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

    <span class="c1"># tmpa = input_ids[:, 16]</span>
    <span class="c1"># print(&#39;tmpa---&gt;&#39;, tmpa, tmpa.shape)       # torch.Size([8]</span>
    <span class="c1"># print(&#39;labels--&gt;&#39;, labels.shape, labels)  # torch.Size([8]</span>

    <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">labels</span>


<span class="c1"># 数据源 数据迭代器 测试</span>
<span class="k">def</span> <span class="nf">dm01_test_dataset</span><span class="p">():</span>

    <span class="c1"># 生成数据源dataset对象</span>
    <span class="n">dataset_train_tmp</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s1">&#39;./mydata1/train.csv&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="c1"># print(&#39;dataset_train_tmp---&gt;&#39;, dataset_train_tmp)</span>

    <span class="c1"># 按照条件过滤数据源对象</span>
    <span class="n">my_dataset_train</span> <span class="o">=</span> <span class="n">dataset_train_tmp</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">32</span><span class="p">)</span>
    <span class="c1"># print(&#39;my_dataset_train---&gt;&#39;, my_dataset_train)</span>
    <span class="c1"># print(&#39;my_dataset_train[0:3]--&gt;&#39;, my_dataset_train[0:3])</span>

    <span class="c1"># 通过dataloader进行迭代</span>
    <span class="n">mydataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">my_dataset_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mydataloader---&gt;&#39;</span><span class="p">,</span> <span class="n">mydataloader</span><span class="p">)</span>

    <span class="c1"># 不训练,不需要计算梯度</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">my_model_pretrained</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># 调整数据迭代器对象数据返回格式</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mydataloader</span><span class="p">):</span>

        <span class="nb">print</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">第1句mask的信息&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">第2句mask的信息&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">break</span>
</code></pre></div>
<blockquote>
<ul>
<li>程序运行效果</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="n">mydataloader</span><span class="o">---&gt;</span> <span class="o">&lt;</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7fbe28611cd0</span><span class="o">&gt;</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">3160</span><span class="p">,</span> <span class="mi">1905</span><span class="p">,</span> <span class="mi">8152</span><span class="p">,</span> <span class="mi">7415</span><span class="p">,</span> <span class="mi">7231</span><span class="p">,</span> <span class="mi">1331</span><span class="p">,</span> <span class="mi">2360</span><span class="p">,</span> <span class="mi">5831</span><span class="p">])</span>

<span class="n">第1句mask的信息</span>
<span class="p">[</span><span class="n">CLS</span><span class="p">]</span> <span class="n">文</span> <span class="n">章</span> <span class="n">总</span> <span class="n">体</span> <span class="n">不</span> <span class="n">错</span> <span class="err">，</span> <span class="n">不</span> <span class="n">过</span> <span class="n">太</span> <span class="n">多</span> <span class="n">的</span> <span class="n">历</span> <span class="n">史</span> <span class="n">资</span> <span class="p">[</span><span class="n">MASK</span><span class="p">]</span> <span class="n">重</span> <span class="n">复</span> <span class="err">，</span> <span class="n">感</span> <span class="n">觉</span> <span class="n">没</span> <span class="n">有</span> <span class="n">步</span> <span class="n">步</span> <span class="n">好</span> <span class="n">看</span> <span class="n">了</span> <span class="err">，</span> <span class="n">作</span> <span class="p">[</span><span class="n">SEP</span><span class="p">]</span>
<span class="n">料</span>

<span class="n">第2句mask的信息</span>
<span class="p">[</span><span class="n">CLS</span><span class="p">]</span> <span class="n">第</span> <span class="n">一</span> <span class="n">散</span> <span class="n">热</span> <span class="n">一</span> <span class="n">般</span> <span class="err">。</span> <span class="err">。</span> <span class="err">。</span> <span class="n">用</span> <span class="n">了</span> <span class="n">一</span> <span class="n">会</span> <span class="n">托</span> <span class="n">腕</span> <span class="p">[</span><span class="n">MASK</span><span class="p">]</span> <span class="n">就</span> <span class="n">发</span> <span class="n">烫</span> <span class="n">了</span><span class="err">?</span> <span class="n">第</span> <span class="n">二</span> <span class="n">液</span> <span class="n">晶</span> <span class="n">屏</span> <span class="n">和</span> <span class="n">主</span> <span class="n">机</span> <span class="n">部</span> <span class="p">[</span><span class="n">SEP</span><span class="p">]</span>
<span class="n">处</span>
<span class="n">迁移学习</span> <span class="n">中文填空</span> <span class="n">End</span>
</code></pre></div>
<h3 id="4_1">4 自定义下游任务网络模型<a class="headerlink" href="#4_1" title="Permanent link">&para;</a></h3>
<blockquote>
<ul>
<li>自定义下游任务网络模型</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="c1"># 定义下游任务模型</span>
<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 定义全连接层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="n">my_tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># 设置全连接层偏置为零</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">my_tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">):</span>
        <span class="c1"># 预训练模型不进行训练</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">my_model_pretrained</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
                             <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                             <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">)</span>

        <span class="c1"># 下游任务进行训练 形状[8,768] ---&gt; [8, 21128]</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">[:,</span> <span class="mi">16</span><span class="p">])</span>

        <span class="c1"># 返回</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div>
<blockquote>
<ul>
<li>模型测试</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="c1"># 模型输入和输出测试</span>
<span class="k">def</span> <span class="nf">dm02_test_mymodel</span><span class="p">():</span>
    <span class="c1"># 生成数据源dataset对象</span>
    <span class="n">dataset_train_tmp</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s1">&#39;./mydata1/train.csv&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="c1"># print(&#39;dataset_train_tmp---&gt;&#39;, dataset_train_tmp)</span>

    <span class="c1"># 按照条件过滤数据源对象</span>
    <span class="n">my_dataset_train</span> <span class="o">=</span> <span class="n">dataset_train_tmp</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">32</span><span class="p">)</span>
    <span class="c1"># print(&#39;my_dataset_train---&gt;&#39;, my_dataset_train)</span>
    <span class="c1"># print(&#39;my_dataset_train[0:3]--&gt;&#39;, my_dataset_train[0:3])</span>

    <span class="c1"># 通过dataloader进行迭代</span>
    <span class="n">mydataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">my_dataset_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mydataloader---&gt;&#39;</span><span class="p">,</span> <span class="n">mydataloader</span><span class="p">)</span>

    <span class="c1"># 不训练,不需要计算梯度</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">my_model_pretrained</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># 实例化下游任务模型</span>
    <span class="n">mymodel</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>

    <span class="c1"># 调整数据迭代器对象数据返回格式</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mydataloader</span><span class="p">):</span>

        <span class="nb">print</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">第1句mask的信息&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">第2句mask的信息&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

        <span class="c1"># 给模型喂数据 [8,768] ---&gt; [8,21128] 填空就是分类 21128个单词中找一个单词</span>
        <span class="n">myout</span> <span class="o">=</span> <span class="n">mymodel</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;myout---&gt;&#39;</span><span class="p">,</span> <span class="n">myout</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">myout</span><span class="p">)</span>
        <span class="k">break</span>
</code></pre></div>
<blockquote>
<ul>
<li>输出效果</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code>mydataloader---&gt; &lt;torch.utils.data.dataloader.DataLoader object at 0x7fd7c0765c10&gt;
torch.Size([8, 32]) torch.Size([8, 32]) torch.Size([8, 32]) tensor([ 702, 6381,  857, 8024, 2218, 1961, 3175, 2141])

第1句mask的信息
[CLS] 很 重, 背 出 去 很 累. 好 象 屏 幕 上 有 [MASK] 亮 点, 不 过 很 小 ( 屏 本 来 就 很 小 [SEP]
个

第2句mask的信息
[CLS] 我 于 11 月 22 日 订 购 了 《 杜 拉 拉 升 职 [MASK] 》 并 已 通 过 银 行 付 款 ， 为 什 么 订 [SEP]
记
myout---&gt; torch.Size([8, 21128]) tensor([[-0.3201,  0.3877,  0.1041,  ...,  0.2262,  0.5397,  0.5053],
        [ 0.0626,  0.1335,  0.7057,  ..., -0.6277, -0.2287, -0.0532],
        [ 0.3807,  0.2024,  0.0514,  ..., -0.0113,  0.3084,  0.4678],
        ...,
        [ 0.3452,  0.1774,  0.0127,  ..., -0.3960,  0.2417, -0.0260],
        [-0.4155,  0.2038,  0.2512,  ..., -0.4112, -0.1052,  0.3574],
        [ 0.3464,  0.3439,  0.6628,  ..., -0.1706,  0.1020,  0.4141]],
       grad_fn=&lt;AddmmBackward&gt;)
</code></pre></div>
<h3 id="5_1">5 模型训练<a class="headerlink" href="#5_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># 模型训练 - 填空</span>
<span class="k">def</span> <span class="nf">dm03_train_model</span><span class="p">():</span>

    <span class="c1"># 实例化数据源对象my_dataset_train</span>
    <span class="n">dataset_train_tmp</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s1">&#39;./mydata1/train.csv&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="n">my_dataset_train</span> <span class="o">=</span> <span class="n">dataset_train_tmp</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;my_dataset_train---&gt;&#39;</span><span class="p">,</span> <span class="n">my_dataset_train</span><span class="p">)</span>

    <span class="c1"># 实例化下游任务模型my_model</span>
    <span class="n">my_model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>

    <span class="c1"># 实例化优化器my_optimizer</span>
    <span class="n">my_optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">my_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>

    <span class="c1"># 实例化损失函数my_criterion</span>
    <span class="n">my_criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="c1"># 不训练预训练模型 只让预训练模型计算数据特征 不需要计算梯度</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">my_model_pretrained</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># 设置训练参数</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="c1"># 设置模型为训练模型</span>
    <span class="n">my_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># 外层for循环 控制轮数</span>
    <span class="k">for</span> <span class="n">eporch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>

        <span class="c1"># 实例化数据迭代器对象my_dataloader</span>
        <span class="n">my_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">my_dataset_train</span><span class="p">,</span>
                                                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                                    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn2</span><span class="p">,</span>
                                                    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                    <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">starttime</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">)(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span>
        <span class="c1"># 内层for循环 控制迭代次数</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">my_dataloader</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
            <span class="c1"># 给模型喂数据 [8,32] --&gt; [8,21128]</span>
            <span class="n">my_out</span> <span class="o">=</span> <span class="n">my_model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
                        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                        <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">)</span>

            <span class="c1"># 计算损失</span>
            <span class="n">my_loss</span> <span class="o">=</span> <span class="n">my_criterion</span><span class="p">(</span><span class="n">my_out</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="c1"># 梯度清零</span>
            <span class="n">my_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># 反向传播</span>
            <span class="n">my_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="c1"># 梯度更新</span>
            <span class="n">my_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># 每5次迭代 算一下准确率</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">my_out</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># [8,21128] --&gt; (8,)</span>
                <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">out</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;轮次:</span><span class="si">%d</span><span class="s1"> 迭代数:</span><span class="si">%d</span><span class="s1"> 损失:</span><span class="si">%.6f</span><span class="s1"> 准确率</span><span class="si">%.3f</span><span class="s1"> 时间</span><span class="si">%d</span><span class="s1">&#39;</span> \
                      <span class="o">%</span><span class="p">(</span><span class="n">eporch_idx</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">my_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">)(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="o">-</span><span class="n">starttime</span><span class="p">))</span>

        <span class="c1"># 每个轮次保存模型</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">my_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;./my_model_mask_</span><span class="si">%d</span><span class="s1">.bin&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">eporch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</code></pre></div>
<blockquote>
<ul>
<li>模型训练效果输出</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">680</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.324525</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间370</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">700</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.776103</span> <span class="n">准确率0</span><span class="mf">.750</span> <span class="n">时间381</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">720</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.681674</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间392</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">740</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.654384</span> <span class="n">准确率0</span><span class="mf">.750</span> <span class="n">时间402</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">760</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.612616</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间413</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">780</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.918874</span> <span class="n">准确率0</span><span class="mf">.625</span> <span class="n">时间424</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">800</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.640087</span> <span class="n">准确率0</span><span class="mf">.750</span> <span class="n">时间435</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">820</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.410612</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间446</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">840</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.395016</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间457</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">860</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.313001</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间468</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">880</span> <span class="n">损失</span><span class="p">:</span><span class="mf">1.534165</span> <span class="n">准确率0</span><span class="mf">.750</span> <span class="n">时间479</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">900</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.384014</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间490</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">920</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.386283</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间501</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">940</span> <span class="n">损失</span><span class="p">:</span><span class="mf">1.168535</span> <span class="n">准确率0</span><span class="mf">.750</span> <span class="n">时间512</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">960</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.568617</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间522</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">980</span> <span class="n">损失</span><span class="p">:</span><span class="mf">1.178597</span> <span class="n">准确率0</span><span class="mf">.750</span> <span class="n">时间533</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">1000</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.534274</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间544</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">1020</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.371301</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间555</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">1040</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.106059</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间566</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">1060</span> <span class="n">损失</span><span class="p">:</span><span class="mf">1.153722</span> <span class="n">准确率0</span><span class="mf">.750</span> <span class="n">时间577</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">1080</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.352150</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间588</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">1100</span> <span class="n">损失</span><span class="p">:</span><span class="mf">1.242567</span> <span class="n">准确率0</span><span class="mf">.625</span> <span class="n">时间598</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">2</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">1120</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.548795</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间609</span>
<span class="c1"># 只需要3个轮次，就可以填空准确率达到88%以上</span>
</code></pre></div>
<h3 id="6_1">6 模型评估<a class="headerlink" href="#6_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># 模型测试：填空</span>
<span class="k">def</span> <span class="nf">dm04_evaluate_model</span><span class="p">():</span>

    <span class="c1"># 实例化数据源对象my_dataset_test</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">加载测试集&#39;</span><span class="p">)</span>
    <span class="n">my_dataset_tmp</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s1">&#39;./mydata1/test.csv&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="n">my_dataset_test</span> <span class="o">=</span> <span class="n">my_dataset_tmp</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">32</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;my_dataset_test---&gt;&#39;</span><span class="p">,</span> <span class="n">my_dataset_test</span><span class="p">)</span>
    <span class="c1"># print(my_dataset_test[0:3])</span>

    <span class="c1"># 实例化下游任务模型my_model</span>
    <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;./my_model_mask_3.bin&#39;</span>
    <span class="n">my_model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
    <span class="n">my_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;my_model--&gt;&#39;</span><span class="p">,</span> <span class="n">my_model</span><span class="p">)</span>

    <span class="c1"># 设置下游任务模型为评估模式</span>
    <span class="n">my_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># 设置评估参数</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># 实例化化dataloader</span>
    <span class="n">my_loader_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">my_dataset_test</span><span class="p">,</span>
                                              <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                              <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn2</span><span class="p">,</span>
                                              <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                              <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># 给模型送数据 测试预测结果</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span>
            <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">my_loader_test</span><span class="p">):</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">my_out</span> <span class="o">=</span> <span class="n">my_model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
                        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                        <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">my_out</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">out</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;预测值:&#39;</span><span class="p">,</span> <span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">真实值:&#39;</span><span class="p">,</span> <span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
</code></pre></div>
<blockquote>
<ul>
<li>输出效果:</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code>26 [CLS] 大 堂 是 喧 闹 的 ， 房 间 地 毯 是 脏 的 ， [MASK] 室 淋 浴 龙 头 是 坏 的 ， 毛 巾 是 黄 颜 [SEP]
预测值: 寝  真实值: 浴
0.62
51 [CLS] 外 观 漂 亮 ， 13 寸 黄 金 比 例 ， 悬 浮 键 [MASK] 设 计 ， 噪 音 很 低 ， 和 我 公 司 发 的 [SEP]
预测值: 盘  真实值: 盘
0.6625
76 [CLS] 某 些 酒 店 人 员 对 待 顾 客 不 诚 恳 。 说 [MASK] 你 换 房 间 ， 骗 你 说 是 价 钱 贵 的 房 [SEP]
预测值: 让  真实值: 给
0.68
101 [CLS] 看 这 本 书 有 种 感 觉 就 是 作 者 在 苦 口 [MASK] 心 的 告 戒 读 者 如 何 如 何 ， 为 了 证 [SEP]
预测值: 婆  真实值: 婆
0.6775
126 [CLS] 房 间 很 舒 适 也 很 干 净 ， 周 围 虽 然 不 [MASK] 闹 但 很 安 静 ， 离 虹 桥 机 场 很 静 ， [SEP]
预测值: 吵  真实值: 热
0.681
</code></pre></div>
<h2 id="4-">4 迁移学习-中文句子关系<a class="headerlink" href="#4-" title="Permanent link">&para;</a></h2>
<h3 id="1_3">1 任务介绍<a class="headerlink" href="#1_3" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">下一句话任务NSP</span><span class="p">(</span><span class="n">Next</span> <span class="n">Sentence</span> <span class="n">Prediction</span><span class="p">)</span> <span class="n">中文句子关系任务</span><span class="err">。</span><span class="n">输入2句话</span><span class="err">，</span><span class="n">判断第二句是否为第一句的下半句</span><span class="err">。</span>
</code></pre></div>
<h3 id="2_2">2 数据介绍<a class="headerlink" href="#2_2" title="Permanent link">&para;</a></h3>
<ul>
<li>数据文件有三个train.csv，test.csv，validation.csv，数据样式都是一样的。</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">label</span><span class="p">,</span><span class="n">text</span>
<span class="mi">1</span><span class="p">,</span><span class="n">选择珠江花园的原因就是方便</span><span class="err">，</span><span class="n">有电动扶梯直接到达海边</span><span class="err">，</span><span class="n">周围餐馆</span><span class="err">、</span><span class="n">食廊</span><span class="err">、</span><span class="n">商场</span><span class="err">、</span><span class="n">超市</span><span class="err">、</span><span class="n">摊位一应俱全</span><span class="err">。</span><span class="n">酒店装修一般</span><span class="err">，</span><span class="n">但还算整洁</span><span class="err">。</span> <span class="n">泳池在大堂的屋顶</span><span class="err">，</span><span class="n">因此很小</span><span class="err">，</span><span class="n">不过女儿倒是喜欢</span><span class="err">。</span> <span class="n">包的早餐是西式的</span><span class="err">，</span><span class="n">还算丰富</span><span class="err">。</span> <span class="n">服务吗</span><span class="err">，</span><span class="n">一般</span>
<span class="mi">1</span><span class="p">,</span><span class="mf">15.4</span><span class="n">寸笔记本的键盘确实爽</span><span class="err">，</span><span class="n">基本跟台式机差不多了</span><span class="err">，</span><span class="n">蛮喜欢数字小键盘</span><span class="err">，</span><span class="n">输数字特方便</span><span class="err">，</span><span class="n">样子也很美观</span><span class="err">，</span><span class="n">做工也相当不错</span>
<span class="mi">0</span><span class="p">,</span><span class="n">房间太小</span><span class="err">。</span><span class="n">其他的都一般</span><span class="err">。。。。。。。。。</span>
<span class="mi">0</span><span class="p">,</span><span class="s2">&quot;1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸，一摸一个印. 4.硬盘分区不好办.&quot;</span>
<span class="mi">1</span><span class="p">,</span><span class="s2">&quot;今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量商量,单独出个第6卷,让我们的孩子不会有所遗憾。&quot;</span>
</code></pre></div>
<ul>
<li>导入工具包和辅助工具实例化对象</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertModel</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># 加载字典和分词工具</span>
<span class="n">my_tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-chinese&#39;</span><span class="p">)</span>

<span class="c1"># 加载预训练模型</span>
<span class="n">my_model_pretrained</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;bert-base-chinese&#39;</span><span class="p">)</span>
</code></pre></div>
<h3 id="3_2">3 数据预处理<a class="headerlink" href="#3_2" title="Permanent link">&para;</a></h3>
<p>对持久化文件中数据进行处理，以满足模型训练要求。</p>
<blockquote>
<ul>
<li>数据预处理和相关测试函数</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="c1"># 定义数据源类</span>
<span class="k">class</span> <span class="nc">MyDataSet</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_csv_files</span><span class="p">):</span>

        <span class="c1"># 生成数据源dataset对象</span>
        <span class="n">my_dataset_temp</span><span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="n">data_csv_files</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
        <span class="c1"># print(&#39;my_dataset_temp---&gt;&#39;, my_dataset_temp)</span>

        <span class="c1"># 按照条件过滤数据源对象</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">my_dataset</span> <span class="o">=</span> <span class="n">my_dataset_temp</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">44</span><span class="p">)</span>
        <span class="c1"># print(&#39;self.my_dataset---&gt;&#39;, self.my_dataset)</span>
        <span class="c1"># print(&#39;self.my_dataset[0:3]--&gt;&#39;, self.my_dataset[0:3])</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">my_dataset</span><span class="p">)</span>
        <span class="k">return</span>  <span class="bp">self</span><span class="o">.</span><span class="n">len</span> <span class="c1"># 7472</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="c1"># 1是下一句话 0不是下一句</span>
        <span class="n">label</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">my_dataset</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="s1">&#39;text&#39;</span><span class="p">]</span>
        <span class="n">sentence1</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">22</span><span class="p">]</span>
        <span class="n">sentence2</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="mi">22</span><span class="p">:</span><span class="mi">44</span><span class="p">]</span>

        <span class="c1"># 产生负样本: 随机产生0和1 一般概率选中0, 替换为无关的一句话</span>
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">j</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">sentence2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">my_dataset</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="s1">&#39;text&#39;</span><span class="p">][</span><span class="mi">22</span><span class="p">:</span><span class="mi">44</span><span class="p">]</span>
            <span class="n">label</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># 返回两句话 和两句话之间的关系</span>
        <span class="k">return</span> <span class="n">sentence1</span><span class="p">,</span> <span class="n">sentence2</span><span class="p">,</span> <span class="n">label</span>


<span class="c1"># 数据集处理自定义函数</span>
<span class="k">def</span> <span class="nf">collate_fn3</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">sents</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>

    <span class="c1"># 文本数值化</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">my_tokenizer</span><span class="o">.</span><span class="n">batch_encode_plus</span><span class="p">(</span><span class="n">batch_text_or_text_pairs</span><span class="o">=</span><span class="n">sents</span><span class="p">,</span>
                                   <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                   <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span>
                                   <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="c1"># 44+cls+sep+sep+other = 44+3=47</span>
                                   <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">,</span>
                                   <span class="n">return_length</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># input_ids 编码之后的数字</span>
    <span class="c1"># attention_mask 是补零的位置是0,其他位置是1</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span>
    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span>
    <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;token_type_ids&#39;</span><span class="p">]</span>

    <span class="c1"># 注意labels不要忘记需要转成tensor 1维数组</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">labels</span>
</code></pre></div>
<blockquote>
<ul>
<li>数据源 数据迭代器测试</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="c1"># 定义数据源 DataSet</span>
<span class="k">def</span> <span class="nf">dm01_test_dataset</span><span class="p">():</span>

    <span class="n">data_files</span> <span class="o">=</span> <span class="s1">&#39;./mydata1/train.csv&#39;</span>
    <span class="n">mydataset</span> <span class="o">=</span> <span class="n">MyDataSet</span><span class="p">(</span><span class="n">data_files</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mydataset--&gt;&#39;</span><span class="p">,</span> <span class="n">mydataset</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mydataset</span><span class="p">))</span>
    <span class="c1"># print(mydataset[3])</span>

    <span class="c1"># 通过dataloader进行迭代</span>
    <span class="n">mydataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">mydataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn3</span><span class="p">,</span> <span class="n">Tshuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mydataloader---&gt;&#39;</span><span class="p">,</span> <span class="n">mydataloader</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="n">mydataloader</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="c1"># 打印每个批次的第1句话</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="k">break</span>
</code></pre></div>
<blockquote>
<ul>
<li>程序运行效果</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="n">mydataset</span><span class="o">--&gt;</span> <span class="o">&lt;</span><span class="n">__main__</span><span class="o">.</span><span class="n">MyDataSet</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7fb4a8471ad0</span><span class="o">&gt;</span> <span class="mi">7472</span>
<span class="n">mydataloader</span><span class="o">---&gt;</span> <span class="o">&lt;</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7fb44835d8d0</span><span class="o">&gt;</span>
<span class="c1"># 下面2句话 不是上下文关系</span>
<span class="p">[</span><span class="n">CLS</span><span class="p">]</span> <span class="n">选</span> <span class="n">择</span> <span class="n">珠</span> <span class="n">江</span> <span class="n">花</span> <span class="n">园</span> <span class="n">的</span> <span class="n">原</span> <span class="n">因</span> <span class="n">就</span> <span class="n">是</span> <span class="n">方</span> <span class="n">便</span> <span class="err">，</span> <span class="n">有</span> <span class="n">电</span> <span class="n">动</span> <span class="n">扶</span> <span class="n">梯</span> <span class="n">直</span> <span class="n">接</span> <span class="n">到</span> <span class="p">[</span><span class="n">SEP</span><span class="p">]</span> <span class="n">达</span> <span class="n">海</span> <span class="n">边</span> <span class="err">，</span> <span class="n">周</span> <span class="n">围</span> <span class="n">餐</span> <span class="n">馆</span> <span class="err">、</span> <span class="n">食</span> <span class="n">廊</span> <span class="err">、</span> <span class="n">商</span> <span class="n">场</span> <span class="err">、</span> <span class="n">超</span> <span class="n">市</span> <span class="err">、</span> <span class="n">摊</span> <span class="n">位</span> <span class="n">一</span> <span class="n">应</span> <span class="p">[</span><span class="n">SEP</span><span class="p">]</span> <span class="p">[</span><span class="n">PAD</span><span class="p">]</span> <span class="p">[</span><span class="n">PAD</span><span class="p">]</span> <span class="p">[</span><span class="n">PAD</span><span class="p">]</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1"># 下面2句话 是上线文关系</span>
<span class="p">[</span><span class="n">CLS</span><span class="p">]</span> <span class="n">选</span> <span class="n">择</span> <span class="n">珠</span> <span class="n">江</span> <span class="n">花</span> <span class="n">园</span> <span class="n">的</span> <span class="n">原</span> <span class="n">因</span> <span class="n">就</span> <span class="n">是</span> <span class="n">方</span> <span class="n">便</span> <span class="err">，</span> <span class="n">有</span> <span class="n">电</span> <span class="n">动</span> <span class="n">扶</span> <span class="n">梯</span> <span class="n">直</span> <span class="n">接</span> <span class="n">到</span> <span class="p">[</span><span class="n">SEP</span><span class="p">]</span> <span class="n">忙</span> <span class="n">忙</span> <span class="n">碌</span> <span class="n">碌</span> <span class="n">镇</span> <span class="n">和</span> <span class="n">青</span> <span class="n">蛙</span> <span class="n">弗</span> <span class="n">洛</span> <span class="n">格</span> <span class="n">的</span> <span class="n">成</span> <span class="n">长</span> <span class="n">故</span> <span class="n">事</span> <span class="err">，</span> <span class="n">那</span> <span class="n">几</span> <span class="n">本</span> <span class="n">书</span> <span class="n">我</span> <span class="p">[</span><span class="n">SEP</span><span class="p">]</span> <span class="p">[</span><span class="n">PAD</span><span class="p">]</span> <span class="p">[</span><span class="n">PAD</span><span class="p">]</span> <span class="p">[</span><span class="n">PAD</span><span class="p">]</span>
</code></pre></div>
<h3 id="4_2">4 自定义下游任务网络模型<a class="headerlink" href="#4_2" title="Permanent link">&para;</a></h3>
<blockquote>
<ul>
<li>自定义下游任务网络模型</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="c1"># 定义下游任务模型NSP</span>
<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># 定义全连接层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">):</span>

        <span class="c1"># 预训练模型不训练</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">my_model_pretrained</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
                       <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                       <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">)</span>

        <span class="c1"># 下游任务模型训练 数据经过全连接层</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>

        <span class="c1"># 数据进行softmax归一化 分类概率值</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
</code></pre></div>
<blockquote>
<ul>
<li>模型测试</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="c1"># NSP模型输入和输出测试</span>
<span class="k">def</span> <span class="nf">dm02_test_mymodel</span><span class="p">():</span>

    <span class="n">data_files</span> <span class="o">=</span> <span class="s1">&#39;./mydata1/train.csv&#39;</span>
    <span class="n">mydataset</span> <span class="o">=</span> <span class="n">MyDataSet</span><span class="p">(</span><span class="n">data_files</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mydataset--&gt;&#39;</span><span class="p">,</span> <span class="n">mydataset</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mydataset</span><span class="p">))</span>

    <span class="c1"># 通过dataloader进行迭代</span>
    <span class="n">mydataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">mydataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mydataloader---&gt;&#39;</span><span class="p">,</span> <span class="n">mydataloader</span><span class="p">)</span>

    <span class="c1"># 实例化下游任务模型</span>
    <span class="n">mymodel</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>

    <span class="c1"># 给模型喂数据</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="n">mydataloader</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">my_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

        <span class="c1"># 给模型喂数据 [8,768] ---&gt; [8,2] nsp任务是二分类</span>
        <span class="n">myout</span> <span class="o">=</span> <span class="n">mymodel</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;myout---&gt;&#39;</span><span class="p">,</span> <span class="n">myout</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">myout</span><span class="p">)</span>
        <span class="k">break</span>
</code></pre></div>
<blockquote>
<ul>
<li>输出效果</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code>mydataset--&gt; &lt;__main__.MyDataSet object at 0x7fe4b86b8610&gt; 7472

mydataloader---&gt; &lt;torch.utils.data.dataloader.DataLoader object at 0x7fe4d8b4ad50&gt;

# 这2句话 第2句话是第1句话的下文
[CLS] 我 家 小 宝 同 学 特 别 喜 爱 卡 梅 拉 系 列 故 事, 每 天 晚 上 [SEP] 睡 觉 前 非 讲 不 可, 那 些 可 爱 的 故 事 会 陪 着 他 进 入 梦 [SEP] [PAD] [PAD] [PAD]

torch.Size([8, 50]) torch.Size([8, 50]) torch.Size([8, 50]) tensor([1, 0, 1, 1, 1, 1, 0, 1])
myout---&gt; torch.Size([8, 2]) tensor([[0.8149, 0.1851],
        [0.4211, 0.5789],
        [0.7687, 0.2313],
        [0.7724, 0.2276],
        [0.7527, 0.2473],
        [0.7036, 0.2964],
        [0.7887, 0.2113],
        [0.7259, 0.2741]], grad_fn=&lt;SoftmaxBackward&gt;)

# 这2句话 第2句话不是第1句话的下文
[CLS] 昨 天 我 把 这 套 书 看 完 了 ， 结 尾 我 不 是 很 喜 欢 有 点 太 [SEP] 一 部 分 没 意 思, 而 且 不 值 那 么 多 钱, 上 当 了, 现 在 [SEP] [PAD] [PAD] [PAD]
</code></pre></div>
<h3 id="5_2">5 模型训练<a class="headerlink" href="#5_2" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># 模型训练NSP</span>
<span class="k">def</span> <span class="nf">dm03_train_model</span><span class="p">():</span>

    <span class="n">data_files</span> <span class="o">=</span> <span class="s1">&#39;./mydata1/train.csv&#39;</span>
    <span class="n">mydataset</span> <span class="o">=</span> <span class="n">MyDataSet</span><span class="p">(</span><span class="n">data_files</span><span class="p">)</span>
    <span class="c1"># print(&#39;mydataset--&gt;&#39;, mydataset, len(mydataset))</span>
    <span class="c1"># print(mydataset[3])</span>

    <span class="c1"># 实例化下游任务模型my_model</span>
    <span class="n">my_model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>

    <span class="c1"># 实例化优化器my_optimizer</span>
    <span class="n">my_optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">my_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>

    <span class="c1"># 实例化损失函数my_criterion</span>
    <span class="n">my_criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="c1"># 不训练预训练模型 只让预训练模型计算数据特征 不需要计算梯度</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">my_model_pretrained</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># 设置训练参数</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="c1"># 设置模型为训练模型</span>
    <span class="n">my_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># 外层for循环 控制轮数</span>
    <span class="k">for</span> <span class="n">eporch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>

        <span class="c1"># 实例化数据迭代器对象my_dataloader</span>
        <span class="n">my_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">mydataset</span><span class="p">,</span>
                                                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                                    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn3</span><span class="p">,</span>
                                                    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                    <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">starttime</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">)(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span>

        <span class="c1"># 内存for循环 控制迭代次数</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">my_dataloader</span><span class="p">):</span>
            <span class="c1"># 给模型喂数据 [8,50] --&gt; [8,2]</span>
            <span class="n">my_out</span> <span class="o">=</span> <span class="n">my_model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
                        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                        <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">)</span>

            <span class="c1"># 计算损失</span>
            <span class="n">my_loss</span> <span class="o">=</span> <span class="n">my_criterion</span><span class="p">(</span><span class="n">my_out</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="c1"># 梯度清零</span>
            <span class="n">my_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># 反向传播</span>
            <span class="n">my_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="c1"># 梯度更新</span>
            <span class="n">my_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># 每5次迭代 算一下准确率</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">my_out</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># [8,2] --&gt; (8,)</span>
                <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">out</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;轮次:</span><span class="si">%d</span><span class="s1"> 迭代数:</span><span class="si">%d</span><span class="s1"> 损失:</span><span class="si">%.6f</span><span class="s1"> 准确率</span><span class="si">%.3f</span><span class="s1"> 时间</span><span class="si">%d</span><span class="s1">&#39;</span> \
                      <span class="o">%</span><span class="p">(</span><span class="n">eporch_idx</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">my_loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">)(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">())</span><span class="o">-</span><span class="n">starttime</span><span class="p">))</span>

        <span class="c1"># 每个轮次保存模型</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">my_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;./my_model_nsp_</span><span class="si">%d</span><span class="s1">.bin&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">eporch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</code></pre></div>
<blockquote>
<ul>
<li>模型训练效果输出</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">20</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.535745</span> <span class="n">准确率0</span><span class="mf">.750</span> <span class="n">时间13</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">40</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.389325</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间26</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">60</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.361616</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间39</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">80</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.417564</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间52</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">100</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.375896</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间65</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">120</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.402824</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间78</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">140</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.650159</span> <span class="n">准确率0</span><span class="mf">.625</span> <span class="n">时间91</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">160</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.541370</span> <span class="n">准确率0</span><span class="mf">.625</span> <span class="n">时间104</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">180</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.613911</span> <span class="n">准确率0</span><span class="mf">.625</span> <span class="n">时间117</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">200</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.449493</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间130</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">220</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.545564</span> <span class="n">准确率0</span><span class="mf">.750</span> <span class="n">时间143</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">240</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.314993</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间156</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">260</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.409358</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间169</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">280</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.513622</span> <span class="n">准确率0</span><span class="mf">.750</span> <span class="n">时间182</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">300</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.360398</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间197</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">320</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.430326</span> <span class="n">准确率0</span><span class="mf">.875</span> <span class="n">时间210</span>
<span class="n">轮次</span><span class="p">:</span><span class="mi">0</span> <span class="n">迭代数</span><span class="p">:</span><span class="mi">340</span> <span class="n">损失</span><span class="p">:</span><span class="mf">0.379781</span> <span class="n">准确率1</span><span class="mf">.000</span> <span class="n">时间224</span>
</code></pre></div>
<h3 id="6_2">6 模型评估<a class="headerlink" href="#6_2" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># 模型测试</span>
<span class="k">def</span> <span class="nf">dm04_evaluate_model</span><span class="p">():</span>

    <span class="c1"># 实例化数据源对象my_dataset_test</span>
    <span class="n">data_files</span> <span class="o">=</span> <span class="s1">&#39;./mydata1/train.csv&#39;</span>
    <span class="n">mydataset</span> <span class="o">=</span> <span class="n">MyDataSet</span><span class="p">(</span><span class="n">data_files</span><span class="p">)</span>

    <span class="c1"># 实例化下游任务模型my_model</span>
    <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;./my_model_nsp_3.bin&#39;</span>
    <span class="n">my_model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
    <span class="n">my_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;my_model--&gt;&#39;</span><span class="p">,</span> <span class="n">my_model</span><span class="p">)</span>

    <span class="c1"># 设置下游任务模型为评估模式</span>
    <span class="n">my_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="c1"># 设置评估参数</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># 实例化化dataloader</span>
    <span class="n">my_loader_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">mydataset</span><span class="p">,</span>
                                              <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                                              <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn3</span><span class="p">,</span>
                                              <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                              <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># 给模型送数据 测试预测结果</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">,</span>
            <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">my_loader_test</span><span class="p">):</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">my_out</span> <span class="o">=</span> <span class="n">my_model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
                        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                        <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">my_out</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">out</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
</code></pre></div>
<blockquote>
<ul>
<li>输出效果:</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code># 每20次迭代 打印一下准确率
0.875
0.9047619047619048
0.8871951219512195
0.8954918032786885
0.8981481481481481
0.8960396039603961
0.8915289256198347
0.8874113475177305
0.8843167701863354
0.8867403314917127
0.8868159203980099
0.8829185520361991
0.8858921161825726
0.8874521072796935
0.8883451957295374
0.8899501661129569
</code></pre></div>
<h2 id="5-">5 迁移学习-微调脚本中文分类<a class="headerlink" href="#5-" title="Permanent link">&para;</a></h2>
<h3 id="1_4">1 数据介绍<a class="headerlink" href="#1_4" title="Permanent link">&para;</a></h3>
<ul>
<li>使用文本二分类的任务类型SST-2的微调脚本微调中文预训练模型, 后接带有分类输出头的预定义网络输出结果. 目标是判断句子的情感倾向</li>
<li>准备中文酒店评论的情感分析语料, 语料样式与SST-2数据集相同, 标签0代表差评, 标签1好评</li>
<li>
<p>语料存放在与glue_data/同级目录cn_data/下, 其中的SST-2目录包含train.csv和dev.csv</p>
</li>
<li>
<p>train.csv</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code>sentence    label
早餐不好,服务不到位,晚餐无西餐,早餐晚餐相同,房间条件不好,餐厅不分吸烟区.房间不分有无烟房.    0
去的时候 ,酒店大厅和餐厅在装修,感觉大厅有点挤.由于餐厅装修本来该享受的早饭,也没有享受(他们是8点开始每个房间送,但是我时间来不及了)不过前台服务员态度好!    1
有很长时间没有在西藏大厦住了，以前去北京在这里住的较多。这次住进来发现换了液晶电视，但网络不是很好，他们自己说是收费的原因造成的。其它还好。  1
非常好的地理位置，住的是豪华海景房，打开窗户就可以看见栈桥和海景。记得很早以前也住过，现在重新装修了。总的来说比较满意，以后还会住   1
交通很方便，房间小了一点，但是干净整洁，很有香港的特色，性价比较高，推荐一下哦 1
酒店的装修比较陈旧，房间的隔音，主要是卫生间的隔音非常差，只能算是一般的    0
酒店有点旧，房间比较小，但酒店的位子不错，就在海边，可以直接去游泳。8楼的海景打开窗户就是海。如果想住在热闹的地带，这里不是一个很好的选择，不过威海城市真的比较小，打车还是相当便宜的。晚上酒店门口出租车比较少。   1
位置很好，走路到文庙、清凉寺5分钟都用不了，周边公交车很多很方便，就是出租车不太爱去（老城区路窄爱堵车），因为是老宾馆所以设施要陈旧些，    1
酒店设备一般，套房里卧室的不能上网，要到客厅去。    0
</code></pre></div>
<ul>
<li>dev.csv</li>
</ul>
<div class="highlight"><pre><span></span><code>sentence    label
房间里有电脑，虽然房间的条件略显简陋，但环境、服务还有饭菜都还是很不错的。如果下次去无锡，我还是会选择这里的。 1
我们是5月1日通过携程网入住的，条件是太差了，根本达不到四星级的标准，所有的东西都很陈旧，卫生间水龙头用完竟关不上，浴缸的漆面都掉了，估计是十年前的四星级吧，总之下次是不会入住了。  0
离火车站很近很方便。住在东楼标间，相比较在九江住的另一家酒店，房间比较大。卫生间设施略旧。服务还好。10元中式早餐也不错，很丰富，居然还有青菜肉片汤。 1
坐落在香港的老城区，可以体验香港居民生活，门口交通很方便，如果时间不紧，坐叮当车很好呀！周围有很多小餐馆，早餐就在中远后面的南北嚼吃的，东西很不错。我们定的大床房，挺安静的，总体来说不错。前台结账没有银联！ 1
酒店前台服务差，对待客人不热情。号称携程没有预定。感觉是客人在求他们，我们一定得住。这样的宾馆下次不会入住！  0
价格确实比较高，而且还没有早餐提供。  1
是一家很实惠的酒店，交通方便，房间也宽敞，晚上没有电话骚扰，住了两次，有一次住５０１房间，洗澡间排水不畅通，也许是个别问题．服务质量很好，刚入住时没有调好宽带，服务员很快就帮忙解决了．    1
位置非常好，就在西街的街口，但是却闹中取静，环境很清新优雅。  1
房间应该超出30平米,是HK同级酒店中少有的大;重装之后,设备也不错. 1
</code></pre></div>
<ul>
<li>语料在服务器上存放路径展示</li>
</ul>
<p><img alt="image-20220515125136740" src="img2/image-20220515125136740.png" /></p>
<h3 id="2_3">2 运行代码<a class="headerlink" href="#2_3" title="Permanent link">&para;</a></h3>
<p>在run_glue.py同级目录执行以下命令</p>
<div class="highlight"><pre><span></span><code><span class="c1"># 定义DATA_DIR: 微调数据所在路径, 这里我们使用glue_data中的数据作为微调数据</span>
<span class="c1"># export DATA_DIR=&quot;/root/data/glue_data&quot; # 目前版本暂不需要</span>

<span class="c1"># 定义SAVE_DIR: 模型的保存路径, 我们将模型保存在当前目录的bert_finetuning_test文件中</span>
<span class="nb">export</span> <span class="nv">SAVE_DIR</span><span class="o">=</span><span class="s2">&quot;./bert_finetuning_sst2_test/&quot;</span>

<span class="c1"># 使用python运行微调脚本</span>
<span class="c1"># --model_name_or_path: 选择具体的模型或者变体, 中文语料上微调, 选择bert-base-uncased</span>
<span class="c1"># --task_name: 它将代表对应的任务类型, 如MRPC代表句子对二分类任务</span>
<span class="c1"># --do_train: 使用微调脚本进行训练</span>
<span class="c1"># --do_eval: 使用微调脚本进行验证</span>
<span class="c1"># --max_seq_length: 输入句子的最大长度, 超过则截断, 不足则补齐</span>
<span class="c1"># --learning_rate: 学习率</span>
<span class="c1"># --num_train_epochs: 训练轮数</span>
<span class="c1"># --output_dir $SAVE_DIR: 训练后的模型保存路径</span>
<span class="c1"># --overwrite_output_dir: 再次训练时将清空之前的保存路径内容重新写入</span>

<span class="c1"># 注1 虚拟机中执行以下命令耗时较长，建议在有GPU的主机上执行</span>
<span class="c1"># 注2 该命令已在虚拟机执行，再次执行会覆盖缓存的模型</span>

python run_glue_forcnsst2.py <span class="se">\</span>
  --task_name sst2 <span class="se">\</span>
  --model_name_or_path bert-base-chinese <span class="se">\</span>
  --do_train <span class="se">\</span>
  --do_eval <span class="se">\</span>
  --train_file <span class="s2">&quot;/Users/xxxxxx/transformers/examples/pytorch/text-classification/cn_data/SST-2/train.csv&quot;</span> <span class="se">\</span>
  --validation_file <span class="s2">&quot;/Users/xxxxxx/transformers/examples/pytorch/text-classification/cn_data/SST-2/dev.csv&quot;</span> <span class="se">\</span>
  --max_seq_length <span class="m">128</span> <span class="se">\</span>
  --learning_rate 2e-5 <span class="se">\</span>
  --num_train_epochs <span class="m">1</span>.0 <span class="se">\</span>
  --output_dir <span class="s2">&quot;bert-base-uncased-finetuning&quot;</span> <span class="se">\</span>
  --overwrite_output_dir

<span class="c1"># 注3 本命令已形成mycnsst2.sh shell文件，使用命令直接执行即可。比如： sh mycnnsst2.sh</span>
</code></pre></div>
<blockquote>
<ul>
<li>检验效果</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code># 找到mycnnsst2.sh的文件路径，比如：/Users/xxxxxx/transformers/examples/pytorch/text-classification
(nlp382) xxxxxx@bogon text-classification % sh mycnsst2.sh

# 最终打印模型的验证结果, 准确率高达0.88.

[INFO|trainer.py:2463] 2022-05-15 11:50:30,323 &gt;&gt; ***** Running Evaluation *****
[INFO|trainer.py:2465] 2022-05-15 11:50:30,323 &gt;&gt;   Num examples = 1000
[INFO|trainer.py:2468] 2022-05-15 11:50:30,324 &gt;&gt;   Batch size = 8
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [04:06&lt;00:00,  1.99s/it]05/15/2022 11:54:39 - INFO - datasets.metric - Removing /Users/xxxxxx/.cache/huggingface/metrics/glue/sst2/default_experiment-1-0.arrow
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [04:06&lt;00:00,  1.97s/it]
***** eval metrics *****
  epoch                   =        1.0
  eval_accuracy           =      0.885
  eval_loss               =     0.3328
  eval_runtime            = 0:04:08.99
  eval_samples            =       1000
  eval_samples_per_second =      4.016
  eval_steps_per_second   =      0.502
</code></pre></div>
<h3 id="3_3">3 查看模型文件内容<a class="headerlink" href="#3_3" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code>-rw-r--r--  1        1390  5 15 11:54 README.md
-rw-r--r--  1         389  5 15 11:54 all_results.json
-rw-r--r--  1         216  5 15 11:54 eval_results.json
-rw-r--r--  1         590  5 15 11:50 trainer_state.json
-rw-r--r--  1         193  5 15 11:50 train_results.json
-rw-r--r--  1        3119  5 15 11:50 training_args.bin
-rw-r--r--  1      439390  5 15 11:50 tokenizer.json
-rw-r--r--  1      109540  5 15 11:50 vocab.txt
-rw-r--r--  1         112  5 15 11:50 special_tokens_map.json
-rw-r--r--  1         322  5 15 11:50 tokenizer_config.json
-rw-r--r--  1   409150611  5 15 11:50 pytorch_model.bin
-rw-r--r--  1        1005  5 15 11:50 config.json
</code></pre></div>
<h3 id="4_3">4 使用本地微调模型<a class="headerlink" href="#4_3" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">AutoModel</span>

<span class="k">def</span>  <span class="nf">dm01_use_model</span><span class="p">():</span>

    <span class="c1"># 0 找到自己预训练模型的路径</span>
    <span class="n">mymodelname</span> <span class="o">=</span> <span class="s1">&#39;/Users/xxxx/transformers/examples/pytorch/text-classification/bert-base-uncased-finetuning&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">mymodelname</span><span class="p">)</span>

    <span class="c1"># 1 本地加载预训练模型的tokenizer</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">mymodelname</span><span class="p">)</span>

    <span class="c1"># 2 本地加载 预训练模型 带分类模型头</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">mymodelname</span><span class="p">)</span>
    <span class="c1"># model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)</span>

    <span class="c1"># 3 默认情况下 加载预训练模型，不带头</span>
    <span class="c1"># model2 = AutoModel.from_pretrained(mymodelname)</span>

    <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;早餐不好,服务不到位,晚餐无西餐,早餐晚餐相同,房间条件不好&quot;</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">tokens_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">index</span><span class="p">])</span>

    <span class="c1"># 使用评估模式</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="c1"># 使用模型预测获得结果</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">tokens_tensor</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;result.logits---&gt;&#39;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">logits</span><span class="p">)</span>

    <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">logits</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;预测标签为&gt;&#39;</span><span class="p">,</span> <span class="n">predicted_label</span><span class="p">)</span>

    <span class="n">text1</span> <span class="o">=</span> <span class="s2">&quot;房间应该超出30平米,是HK同级酒店中少有的大;重装之后,设备也不错.&quot;</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text1</span><span class="p">)</span>
    <span class="n">tokens_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">index</span><span class="p">])</span>

    <span class="c1"># 使用评估模式</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="c1"># 使用模型预测获得结果</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">tokens_tensor</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;result.logits---&gt;&#39;</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">logits</span><span class="p">)</span>

    <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;预测标签为&gt;&#39;</span><span class="p">,</span> <span class="n">predicted_label</span><span class="p">)</span>
</code></pre></div>
<blockquote>
<ul>
<li>输出效果:</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code>输入文本为: 早餐不好,服务不到位,晚餐无西餐,早餐晚餐相同,房间条件不好
预测标签为: 0

输入文本为: 房间应该超出30平米,是HK同级酒店中少有的大;重装之后,设备也不错.
预测标签为: 1
</code></pre></div>
<h2 id="6_3">6 小结<a class="headerlink" href="#6_3" title="Permanent link">&para;</a></h2>
<ul>
<li>学习了迁移学习方式中文分类任务开发<ul>
<li>数据预处理、数据源封装、数据迭代器的使用</li>
<li>搭建中文分类任务下游任务模型，并进行模型训练、模型预测</li>
</ul>
</li>
<li>学习了迁移学习方式中文填空任务开发<ul>
<li>数据预处理、数据源封装、数据迭代器的使用</li>
<li>搭建中文填空下游任务模型，并进行模型训练、模型预测</li>
</ul>
</li>
<li>学习了迁移学习方式中文句子关系任务开发<ul>
<li>数据预处理、数据源封装、数据迭代器的使用</li>
<li>搭建中文句子关系任务模型，并进行模型训练、模型预测</li>
</ul>
</li>
</ul>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="页脚">
      
        
        <a href="8%20Transformers%E5%BA%93%E4%BD%BF%E7%94%A8.html" class="md-footer__link md-footer__link--prev" aria-label="上一页: 8 Transformers库使用" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                上一页
              </span>
              8 Transformers库使用
            </div>
          </div>
        </a>
      
      
        
        <a href="10%20NLP%E4%B8%AD%E7%9A%84%E6%A0%87%E5%87%86%E6%95%B0%E6%8D%AE%E9%9B%86%28%E6%8B%93%E5%B1%95%E8%B5%84%E6%96%99%29.html" class="md-footer__link md-footer__link--next" aria-label="下一页: 10 NLP中的标准数据集(拓展资料)" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                下一页
              </span>
              10 NLP中的标准数据集(拓展资料)
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": [], "translations": {"clipboard.copy": "\u590d\u5236", "clipboard.copied": "\u5df2\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.term.missing": "\u7f3a\u5c11", "select.version.title": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "search": "../assets/javascripts/workers/search.22074ed6.min.js"}</script>
    
    
      <script src="../assets/javascripts/bundle.1514a9a0.min.js"></script>
      
        <script src="../js/extra.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>