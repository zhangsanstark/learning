
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../img/logo.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.1.6">
    
    
      
        <title>8 加载和使用预训练模型 old - 自然语言处理基础V4.0</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.cd566b2a.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.e6a45f82.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href=".." title="自然语言处理基础V4.0" class="md-header__button md-logo" aria-label="自然语言处理基础V4.0" data-md-component="logo">
      
  <img src="../img/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            自然语言处理基础V4.0
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              8 加载和使用预训练模型 old
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
    <img src="../assets/images/logo.svg" height="45px" alt="logo">

  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="自然语言处理基础V4.0" class="md-nav__button md-logo" aria-label="自然语言处理基础V4.0" data-md-component="logo">
      
  <img src="../img/logo.png" alt="logo">

    </a>
    自然语言处理基础V4.0
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1">
          第一章 自然语言处理入门
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第一章 自然语言处理入门" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          第一章 自然语言处理入门
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../01_mkdocs_NLP/1_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%85%A5%E9%97%A8.html" class="md-nav__link">
        1 自然语言处理入门
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          第二章 文本预处理
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第二章 文本预处理" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          第二章 文本预处理
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/1%20%E8%AE%A4%E8%AF%86%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86.html" class="md-nav__link">
        1 认识文本预处理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/2%20%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95.html" class="md-nav__link">
        2 文本处理的基本方法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/3%20%E6%96%87%E6%9C%AC%E5%BC%A0%E9%87%8F%E8%A1%A8%E7%A4%BA%E6%96%B9%E6%B3%95.html" class="md-nav__link">
        3 文本张量表示方法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/4%20%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90.html" class="md-nav__link">
        4 文本数据分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/5%20%E6%96%87%E6%9C%AC%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86.html" class="md-nav__link">
        5 文本特征处理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/6%20%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA.html" class="md-nav__link">
        6 文本数据增强
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_mkdocs_preprocess/7%20jieba%E8%AF%8D%E6%80%A7%E5%AF%B9%E7%85%A7%E8%A1%A8.html" class="md-nav__link">
        7 jieba词性对照表
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          第三章 RNN及其变体
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第三章 RNN及其变体" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          第三章 RNN及其变体
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/1%20%E8%AE%A4%E8%AF%86RNN%E6%A8%A1%E5%9E%8B.html" class="md-nav__link">
        1 认识RNN模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/2%20%E4%BC%A0%E7%BB%9FRNN%E6%A8%A1%E5%9E%8B.html" class="md-nav__link">
        2 传统RNN模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/3%20LSTM%E6%A8%A1%E5%9E%8B.html" class="md-nav__link">
        3 LSTM模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/4%20GRU%E6%A8%A1%E5%9E%8B.html" class="md-nav__link">
        4 GRU模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/5%20RNN%E6%A1%88%E4%BE%8B-%E4%BA%BA%E5%90%8D%E5%88%86%E7%B1%BB%E5%99%A8.html" class="md-nav__link">
        5 RNN案例 人名分类器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/6%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D1.html" class="md-nav__link">
        6 注意力机制介绍1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/7%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D2.html" class="md-nav__link">
        7 注意力机制介绍2
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_mkdocs_RNN/8%20RNN%E6%A1%88%E4%BE%8B-seq2seq%E8%8B%B1%E8%AF%91%E6%B3%95.html" class="md-nav__link">
        8 RNN案例 seq2seq英译法
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          第四章 Transformer
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第四章 Transformer" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          第四章 Transformer
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/1%20Transformer%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        1 Transformer背景介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/2%20%E8%AE%A4%E8%AF%86Transformer%E6%9E%B6%E6%9E%84.html" class="md-nav__link">
        2 认识Transformer架构
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/3%20%E8%BE%93%E5%85%A5%E9%83%A8%E5%88%86%E5%AE%9E%E7%8E%B0.html" class="md-nav__link">
        3 输入部分实现
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/4%20%E7%BC%96%E7%A0%81%E5%99%A8%E9%83%A8%E5%88%86%E5%AE%9E%E7%8E%B0.html" class="md-nav__link">
        4 编码器部分实现
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/5%20%E8%A7%A3%E7%A0%81%E5%99%A8%E9%83%A8%E5%88%86%E5%AE%9E%E7%8E%B0.html" class="md-nav__link">
        5 解码器部分实现
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/6%20%E8%BE%93%E5%87%BA%E9%83%A8%E5%88%86%E5%AE%9E%E7%8E%B0.html" class="md-nav__link">
        6 输出部分实现
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_mkdocs_transformer/7%20%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA.html" class="md-nav__link">
        7 模型构建
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          第五章 迁移学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第五章 迁移学习" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          第五章 迁移学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="1%20fasttext%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        1 fasttext工具介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="2%20fasttext%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84.html" class="md-nav__link">
        2 fasttext模型架构
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="3%20fasttext%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html" class="md-nav__link">
        3 fasttext文本分类
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="4%20%E8%AE%AD%E7%BB%83%E8%AF%8D%E5%90%91%E9%87%8F.html" class="md-nav__link">
        4 训练词向量
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="5%20%E8%AF%8D%E5%90%91%E9%87%8F%E8%BF%81%E7%A7%BB.html" class="md-nav__link">
        5 词向量迁移
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="6%20%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5.html" class="md-nav__link">
        6 迁移学习概念
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="7%20NLP%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B.html" class="md-nav__link">
        7 NLP中的常用预训练模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="8%20Transformers%E5%BA%93%E4%BD%BF%E7%94%A8.html" class="md-nav__link">
        8 Transformers库使用
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="9%20%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5.html" class="md-nav__link">
        9 迁移学习实践
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="10%20NLP%E4%B8%AD%E7%9A%84%E6%A0%87%E5%87%86%E6%95%B0%E6%8D%AE%E9%9B%86%28%E6%8B%93%E5%B1%95%E8%B5%84%E6%96%99%29.html" class="md-nav__link">
        10 NLP中的标准数据集(拓展资料)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          第六章 Bert系列模型
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第六章 Bert系列模型" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          第六章 Bert系列模型
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_mkdocs_bert_pretrained_model/1%20BERT%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        1 BERT模型介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_mkdocs_bert_pretrained_model/2%20BERT%E6%A8%A1%E5%9E%8B%E7%89%B9%E7%82%B9.html" class="md-nav__link">
        2 BERT模型特点
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_mkdocs_bert_pretrained_model/3%20BERT%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        3 BERT系列模型介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_mkdocs_bert_pretrained_model/4%20ELMo%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        4 ELMo模型介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_mkdocs_bert_pretrained_model/5%20GPT%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D.html" class="md-nav__link">
        5 GPT模型介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_mkdocs_bert_pretrained_model/6%20BERT%20GPT%20ELMo%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AF%B9%E6%AF%94.html" class="md-nav__link">
        6 BERT GPT ELMo模型的对比
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7">
          第七章 Transformer精选问答(拓展资料)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="第七章 Transformer精选问答(拓展资料)" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          第七章 Transformer精选问答(拓展资料)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_mkdocs_review_model/1%20Transformer%20%E5%90%84%E5%AD%90%E6%A8%A1%E5%9D%97%E4%BD%9C%E7%94%A8.html" class="md-nav__link">
        1 Transformer 各子模块作用
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_mkdocs_review_model/2%20Transformer%20Decoder%E6%A8%A1%E5%9D%97.html" class="md-nav__link">
        2 Transformer Decoder模块
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_mkdocs_review_model/3%20Self-attention%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3.html" class="md-nav__link">
        3 Self attention机制详解
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_mkdocs_review_model/4%20Multi-head%20Attention%E8%AF%A6%E8%A7%A3.html" class="md-nav__link">
        4 Multi head Attention详解
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_mkdocs_review_model/5%20Transformer%E4%BC%98%E5%8A%BF.html" class="md-nav__link">
        5 Transformer优势
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    学习目标
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    1 加载和使用预训练模型的工具
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    2 加载和使用预训练模型的步骤
  </a>
  
    <nav class="md-nav" aria-label="2 加载和使用预训练模型的步骤">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    2.1 确定需要加载的预训练模型并安装依赖包
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-tokenizer" class="md-nav__link">
    2.2 加载预训练模型的映射器tokenizer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23" class="md-nav__link">
    2.3 加载带/不带头的预训练模型
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#24" class="md-nav__link">
    2.4 使用模型获得输出结果
  </a>
  
    <nav class="md-nav" aria-label="2.4 使用模型获得输出结果">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1_1" class="md-nav__link">
    1 使用不带头的模型进行输出
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2_1" class="md-nav__link">
    2 使用带有语言模型头的模型进行输出
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    3 使用带有分类模型头的模型进行输出
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    4 使用带有问答模型头的模型进行输出
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3_1" class="md-nav__link">
    3 小结
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                

  <h1>8 加载和使用预训练模型 old</h1>

<h3 id="_1">学习目标<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h3>
<ul>
<li>了解加载和使用预训练模型的工具.</li>
<li>掌握加载和使用预训练模型的过程.</li>
</ul>
<h2 id="1">1 加载和使用预训练模型的工具<a class="headerlink" href="#1" title="Permanent link">&para;</a></h2>
<ul>
<li>在这里我们使用Transformers工具包进行模型的加载和使用.</li>
<li>这些预训练模型由世界先进的NLP研发团队huggingface提供.</li>
<li><strong>注意: 下面使用的代码需要国外服务器的资源, 在国内使用的时候, 国内的网站下载可能会出现在原地卡死不动, 或是网络连接超时等一些网络报错, 均是网络问题, 不是代码问题, 这个可以先行跳过, 把主要逻辑梳理完成即可</strong></li>
</ul>
<h2 id="2">2 加载和使用预训练模型的步骤<a class="headerlink" href="#2" title="Permanent link">&para;</a></h2>
<ul>
<li>第一步: 确定需要加载的预训练模型并安装依赖包.</li>
<li>第二步: 加载预训练模型的映射器tokenizer.</li>
<li>第三步: 加载带/不带头的预训练模型.</li>
<li>第四步: 使用模型获得输出结果.</li>
</ul>
<h3 id="21">2.1 确定需要加载的预训练模型并安装依赖包<a class="headerlink" href="#21" title="Permanent link">&para;</a></h3>
<ul>
<li>能够加载哪些模型可以参考前一小结中的常用预训练模型</li>
<li>这里假设我们处理的是中文文本任务, 需要加载的模型是BERT的中文模型: bert-base-chinese</li>
<li>在使用工具加载模型前需要安装必备的依赖包:</li>
</ul>
<div class="highlight"><pre><span></span><code>pip install tqdm boto3 requests regex sentencepiece sacremoses
</code></pre></div>
<h3 id="22-tokenizer">2.2 加载预训练模型的映射器tokenizer<a class="headerlink" href="#22-tokenizer" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">AutoModelForMaskedLM</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">AutoModelForQuestionAnswering</span>

<span class="n">mirror</span><span class="o">=</span><span class="s1">&#39;https://mirrors.tuna.tsinghua.edu.cn/help/hugging-face-models/&#39;</span>

<span class="k">def</span> <span class="nf">demo24_1_load_tokenizer</span><span class="p">():</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-chinese&quot;</span><span class="p">,</span><span class="n">mirror</span><span class="o">=</span><span class="s1">&#39;https://mirrors.tuna.tsinghua.edu.cn/help/hugging-face-models/&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;tokenizer---&gt;&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>

<span class="n">demo24_1_load_tokenizer</span><span class="p">()</span>
</code></pre></div>
<h3 id="23">2.3 加载带/不带头的预训练模型<a class="headerlink" href="#23" title="Permanent link">&para;</a></h3>
<ul>
<li>加载预训练模型时我们可以选择带头或者不带头的模型</li>
<li>这里的'头'是指模型的任务输出层, 选择加载不带头的模型, 相当于使用模型对输入文本进行特征表示.</li>
<li>选择加载带头的模型时, 有三种类型的'头'可供选择,  AutoModelForMaskedLM (语言模型头), AutoModelForSequenceClassification (分类模型头),  AutoModelForQuestionAnswering (问答模型头)</li>
<li>不同类型的'头', 可以使预训练模型输出指定的张量维度. 如使用'分类模型头', 则输出尺寸为(1,2)的张量, 用于进行分类任务判定结果.</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># 加载不带头的预训练模型</span>
<span class="k">def</span> <span class="nf">demo24_2_load_model</span><span class="p">():</span>

    <span class="c1"># 加载的预训练模型的名字</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;bert-base-chinese&#39;</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;加载不带头的预训练模型&#39;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span><span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;model---&gt;&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>


    <span class="c1"># 加载带有语言模型头的预训练模型</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;加载带有语言模型头的预训练模型&#39;</span><span class="p">)</span>
    <span class="n">lm_model</span> <span class="o">=</span><span class="n">AutoModelForMaskedLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;lm_model---&gt;&#39;</span><span class="p">,</span> <span class="n">lm_model</span><span class="p">)</span>

    <span class="c1"># 加载带有分类模型头的预训练模型</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;加载带有分类模型头的预训练模型&#39;</span><span class="p">)</span>
    <span class="n">classification_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;classification_model---&gt;&#39;</span><span class="p">,</span> <span class="n">classification_model</span><span class="p">)</span>

    <span class="c1"># 加载带有问答模型头的预训练模型</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;加载带有问答模型头的预训练模型&#39;</span><span class="p">)</span>
    <span class="n">qa_model</span> <span class="o">=</span> <span class="n">AutoModelForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;qa_model---&gt;&#39;</span><span class="p">,</span> <span class="n">qa_model</span><span class="p">)</span>

<span class="n">demo24_2_load_model</span><span class="p">()</span>
</code></pre></div>
<h3 id="24">2.4 使用模型获得输出结果<a class="headerlink" href="#24" title="Permanent link">&para;</a></h3>
<h4 id="1_1">1 使用不带头的模型进行输出<a class="headerlink" href="#1_1" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">demo24_3_load_AutoModel</span><span class="p">():</span>

    <span class="c1"># 加载的预训练模型的名字</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;bert-base-chinese&#39;</span>

    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-chinese&quot;</span><span class="p">,</span><span class="n">mirror</span><span class="o">=</span><span class="n">mirror</span><span class="p">)</span>

    <span class="c1"># 2 加载model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

    <span class="c1"># 3 使用tokenizer 文本数值化</span>
    <span class="c1"># 输入的中文文本</span>
    <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;人生该如何起头&quot;</span>

    <span class="c1"># 使用tokenizer进行数值映射</span>
    <span class="n">indexed_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>

    <span class="c1"># 打印映射后的结构</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;indexed_tokens:&quot;</span><span class="p">,</span> <span class="n">indexed_tokens</span><span class="p">)</span>

    <span class="c1"># 将映射结构转化为张量输送给不带头的预训练模型</span>
    <span class="n">tokens_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">indexed_tokens</span><span class="p">])</span>

    <span class="c1"># 4 使用不带头的预训练模型获得结果</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">encoded_layers</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">tokens_tensor</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># encoded_layers, _ = model(tokens_tensor)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;不带头的模型输出结果:&quot;</span><span class="p">,</span> <span class="n">encoded_layers</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;不带头的模型输出结果的尺寸:&quot;</span><span class="p">,</span> <span class="n">encoded_layers</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">demo24_3_load_AutoModel</span><span class="p">()</span>
</code></pre></div>
<blockquote>
<ul>
<li>输出效果:</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="c1"># tokenizer映射后的结果, 101和102是起止符, </span>
<span class="c1"># 中间的每个数字对应&quot;人生该如何起头&quot;的每个字.</span>
<span class="n">indexed_tokens</span><span class="p">:</span> <span class="p">[</span><span class="mi">101</span><span class="p">,</span> <span class="mi">782</span><span class="p">,</span> <span class="mi">4495</span><span class="p">,</span> <span class="mi">6421</span><span class="p">,</span> <span class="mi">1963</span><span class="p">,</span> <span class="mi">862</span><span class="p">,</span> <span class="mi">6629</span><span class="p">,</span> <span class="mi">1928</span><span class="p">,</span> <span class="mi">102</span><span class="p">]</span>


<span class="n">不带头的模型输出结果</span><span class="p">:</span> <span class="n">tensor</span><span class="p">([[[</span> <span class="mf">0.5421</span><span class="p">,</span>  <span class="mf">0.4526</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0179</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">1.0447</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1140</span><span class="p">,</span>  <span class="mf">0.0068</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.1343</span><span class="p">,</span>  <span class="mf">0.2785</span><span class="p">,</span>  <span class="mf">0.1602</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0345</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1646</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2186</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.9960</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5121</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6229</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">1.4173</span><span class="p">,</span>  <span class="mf">0.5533</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2681</span><span class="p">],</span>
         <span class="o">...</span><span class="p">,</span>
         <span class="p">[</span> <span class="mf">0.0115</span><span class="p">,</span>  <span class="mf">0.2150</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0163</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">0.6445</span><span class="p">,</span>  <span class="mf">0.2452</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3749</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.8649</span><span class="p">,</span>  <span class="mf">0.4337</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1867</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">0.7397</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2636</span><span class="p">,</span>  <span class="mf">0.2144</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.6207</span><span class="p">,</span>  <span class="mf">0.1668</span><span class="p">,</span>  <span class="mf">0.1561</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">1.1218</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0985</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0937</span><span class="p">]]])</span>


<span class="c1"># 输出尺寸为1x9x768, 即每个字已经使用768维的向量进行了表示,</span>
<span class="c1"># 我们可以基于此编码结果进行接下来的自定义操作, 如: 编写自己的微调网络进行最终输出.</span>
<span class="n">不带头的模型输出结果的尺寸</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">768</span><span class="p">])</span>
</code></pre></div>
<h4 id="2_1">2 使用带有语言模型头的模型进行输出<a class="headerlink" href="#2_1" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">demo24_4_load_AutoLM</span><span class="p">():</span>

    <span class="c1"># 1 加载 tokenizer</span>
    <span class="c1"># 加载的预训练模型的名字</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;bert-base-chinese&#39;</span>

    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-chinese&quot;</span><span class="p">,</span><span class="n">mirror</span><span class="o">=</span><span class="n">mirror</span><span class="p">)</span>

    <span class="c1"># 2 加载model</span>
    <span class="n">lm_model</span> <span class="o">=</span><span class="n">AutoModelForMaskedLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

    <span class="c1"># 3 使用tokenizer 文本数值化</span>
    <span class="c1"># 输入的中文文本</span>
    <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;人生该如何起头&quot;</span>

    <span class="c1"># 使用tokenizer进行数值映射</span>
    <span class="n">indexed_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>

    <span class="c1"># 打印映射后的结构</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;indexed_tokens:&quot;</span><span class="p">,</span> <span class="n">indexed_tokens</span><span class="p">)</span>

    <span class="c1"># 将映射结构转化为张量输送给不带头的预训练模型</span>
    <span class="n">tokens_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">indexed_tokens</span><span class="p">])</span>

    <span class="c1"># 使用带有语言模型头的预训练模型获得结果</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">lm_output</span> <span class="o">=</span> <span class="n">lm_model</span><span class="p">(</span><span class="n">tokens_tensor</span><span class="p">,</span><span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;带语言模型头的模型输出结果:&quot;</span><span class="p">,</span> <span class="n">lm_output</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;带语言模型头的模型输出结果的尺寸:&quot;</span><span class="p">,</span> <span class="n">lm_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">demo24_4_load_AutoLM</span><span class="p">()</span>
</code></pre></div>
<blockquote>
<ul>
<li>输出效果:</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code>带语言模型头的模型输出结果: (tensor([[[ -7.9706,  -7.9119,  -7.9317,  ...,  -7.2174,  -7.0263,  -7.3746],
         [ -8.2097,  -8.1810,  -8.0645,  ...,  -7.2349,  -6.9283,  -6.9856],
         [-13.7458, -13.5978, -12.6076,  ...,  -7.6817,  -9.5642, -11.9928],
         ...,
         [ -9.0928,  -8.6857,  -8.4648,  ...,  -8.2368,  -7.5684, -10.2419],
         [ -8.9458,  -8.5784,  -8.6325,  ...,  -7.0547,  -5.3288,  -7.8077],
         [ -8.4154,  -8.5217,  -8.5379,  ...,  -6.7102,  -5.9782,  -7.6909]]]),)

# 输出尺寸为1x9x21128, 即每个字已经使用21128维的向量进行了表示, 
# 同不带头的模型一样, 我们可以基于此编码结果进行接下来的自定义操作, 如: 编写自己的微调网络进行最终输出.
带语言模型头的模型输出结果的尺寸: torch.Size([1, 9, 21128])
</code></pre></div>
<h4 id="3">3 使用带有分类模型头的模型进行输出<a class="headerlink" href="#3" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">demo24_5_load_AutoSeqC</span><span class="p">():</span>

    <span class="c1"># 1 加载 tokenizer</span>
    <span class="c1"># 加载的预训练模型的名字</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;bert-base-chinese&#39;</span>

    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-chinese&quot;</span><span class="p">,</span><span class="n">mirror</span><span class="o">=</span><span class="n">mirror</span><span class="p">)</span>

    <span class="c1"># 2 加载model</span>
    <span class="n">classification_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

    <span class="c1"># 3 使用tokenizer 文本数值化</span>
    <span class="c1"># 输入的中文文本</span>
    <span class="n">input_text</span> <span class="o">=</span> <span class="s2">&quot;人生该如何起头&quot;</span>

    <span class="c1"># 使用tokenizer进行数值映射</span>
    <span class="n">indexed_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>

    <span class="c1"># 打印映射后的结构</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;indexed_tokens:&quot;</span><span class="p">,</span> <span class="n">indexed_tokens</span><span class="p">)</span>

    <span class="c1"># 将映射结构转化为张量输送给不带头的预训练模型</span>
    <span class="n">tokens_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">indexed_tokens</span><span class="p">])</span>

    <span class="c1"># 使用带有分类模型头的预训练模型获得结果</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">classification_output</span> <span class="o">=</span> <span class="n">classification_model</span><span class="p">(</span><span class="n">tokens_tensor</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;带分类模型头的模型输出结果:&quot;</span><span class="p">,</span> <span class="n">classification_output</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;带分类模型头的模型输出结果的尺寸:&quot;</span><span class="p">,</span> <span class="n">classification_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">demo24_5_load_AutoSeqC</span><span class="p">()</span>
</code></pre></div>
<blockquote>
<ul>
<li>输出效果:</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code>带分类模型头的模型输出结果: (tensor([[-0.0649, -0.1593]]),)
# 输出尺寸为1x2, 可直接用于文本二分问题的输出
带分类模型头的模型输出结果的尺寸: torch.Size([1, 2])
</code></pre></div>
<h4 id="4">4 使用带有问答模型头的模型进行输出<a class="headerlink" href="#4" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">demo24_6_load_AutoQA</span><span class="p">():</span>

    <span class="c1"># 1 加载 tokenizer</span>
    <span class="c1"># 加载的预训练模型的名字</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;bert-base-chinese&#39;</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-chinese&quot;</span><span class="p">,</span><span class="n">mirror</span><span class="o">=</span><span class="n">mirror</span><span class="p">)</span>

    <span class="c1"># 2 加载model</span>
    <span class="n">qa_model</span> <span class="o">=</span> <span class="n">AutoModelForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

    <span class="c1"># 3 使用</span>
    <span class="c1"># 使用带有问答模型头的模型进行输出时, 需要使输入的形式为句子对</span>
    <span class="c1"># 第一条句子是对客观事物的陈述</span>
    <span class="c1"># 第二条句子是针对第一条句子提出的问题</span>
    <span class="c1"># 问答模型最终将得到两个张量,</span>
    <span class="c1"># 每个张量中最大值对应索引的分别代表答案的在文本中的起始位置和终止位置</span>
    <span class="n">input_text1</span> <span class="o">=</span> <span class="s2">&quot;我家的小狗是黑色的&quot;</span>
    <span class="n">input_text2</span> <span class="o">=</span> <span class="s2">&quot;我家的小狗是什么颜色的呢?&quot;</span>

    <span class="c1"># 映射两个句子</span>
    <span class="n">indexed_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">input_text1</span><span class="p">,</span> <span class="n">input_text2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;句子对的indexed_tokens:&quot;</span><span class="p">,</span> <span class="n">indexed_tokens</span><span class="p">)</span>

    <span class="c1"># 输出结果: [101, 2769, 2157, 4638, 2207, 4318, 3221, 7946, 5682, 4638, 102, 2769, 2157, 4638, 2207, 4318, 3221, 784, 720, 7582, 5682, 4638, 1450, 136, 102]</span>
    <span class="c1">#</span>
    <span class="c1"># 用0，1来区分第一条和第二条句子</span>
    <span class="n">segments_ids</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">11</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">14</span>

    <span class="c1"># 转化张量形式</span>
    <span class="n">segments_tensors</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">segments_ids</span><span class="p">])</span>
    <span class="n">tokens_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">indexed_tokens</span><span class="p">])</span>

    <span class="c1"># 使用带有问答模型头的预训练模型获得结果</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span> <span class="o">=</span> <span class="n">qa_model</span><span class="p">(</span><span class="n">tokens_tensor</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="n">segments_tensors</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;带问答模型头的模型输出结果:&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;带问答模型头的模型输出结果的尺寸:&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">start_logits</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">end_logits</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>  <span class="c1"># (torch.Size([1, 25]), torch.Size([1, 25]))</span>

<span class="n">demo24_6_load_AutoQA</span><span class="p">()</span>
</code></pre></div>
<blockquote>
<ul>
<li>输出效果:</li>
</ul>
</blockquote>
<div class="highlight"><pre><span></span><code>句子对的indexed_tokens: [101, 2769, 2157, 4638, 2207, 4318, 3221, 7946, 5682, 4638, 102, 2769, 2157, 4638, 2207, 4318, 3221, 784, 720, 7582, 5682, 4638, 1450, 136, 102]

带问答模型头的模型输出结果: (tensor([[ 0.2574, -0.0293, -0.8337, -0.5135, -0.3645, -0.2216, -0.1625, -0.2768,
         -0.8368, -0.2581,  0.0131, -0.1736, -0.5908, -0.4104, -0.2155, -0.0307,
         -0.1639, -0.2691, -0.4640, -0.1696, -0.4943, -0.0976, -0.6693,  0.2426,
          0.0131]]), tensor([[-0.3788, -0.2393, -0.5264, -0.4911, -0.7277, -0.5425, -0.6280, -0.9800,
         -0.6109, -0.2379, -0.0042, -0.2309, -0.4894, -0.5438, -0.6717, -0.5371,
         -0.1701,  0.0826,  0.1411, -0.1180, -0.4732, -0.1541,  0.2543,  0.2163,
         -0.0042]]))


# 输出为两个形状1x25的张量, 他们是两条句子合并长度的概率分布,
# 第一个张量中最大值所在的索引代表答案出现的起始索引, 
# 第二个张量中最大值所在的索引代表答案出现的终止索引.
带问答模型头的模型输出结果的尺寸: (torch.Size([1, 25]), torch.Size([1, 25]))
</code></pre></div>
<h2 id="3_1">3 小结<a class="headerlink" href="#3_1" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>加载和使用预训练模型的工具:</p>
<ul>
<li>在这里我们使用transformers工具进行模型的加载和使用.</li>
<li>这些预训练模型由世界先进的NLP研发团队huggingface提供.</li>
</ul>
</li>
<li>
<p>加载和使用预训练模型的步骤:</p>
<ul>
<li>第一步: 确定需要加载的预训练模型并安装依赖包.</li>
<li>第二步: 加载预训练模型的映射器tokenizer.</li>
<li>第三步: 加载带/不带头的预训练模型.</li>
<li>第四步: 使用模型获得输出结果.</li>
</ul>
</li>
</ul>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": [], "translations": {"clipboard.copy": "\u590d\u5236", "clipboard.copied": "\u5df2\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.term.missing": "\u7f3a\u5c11", "select.version.title": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "search": "../assets/javascripts/workers/search.22074ed6.min.js"}</script>
    
    
      <script src="../assets/javascripts/bundle.1514a9a0.min.js"></script>
      
        <script src="../js/extra.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>